Loading rhel8/default-amp
  Loading requirement: dot rhel8/slurm singularity/current rhel8/global
    cuda/11.4 libpciaccess/0.16/gcc-9.4.0-6fonbj6
    libiconv/1.16/gcc-9.4.0-ahebbov libxml2/2.9.12/gcc-9.4.0-gnknt5e
    ncurses/6.2/gcc-9.4.0-aiirok7 hwloc/2.5.0/gcc-9.4.0-7sqomga
    libevent/2.1.12/gcc-9.4.0-hgny7cm numactl/2.0.14/gcc-9.4.0-52dwc6n
    cuda/11.4.0/gcc-9.4.0-3hnxhjt gdrcopy/2.2/gcc-9.4.0-e4igtfp
    knem/1.1.4/gcc-9.4.0-bpbxgva libnl/3.3.0/gcc-9.4.0-whwhrwb
    rdma-core/34.0/gcc-9.4.0-5eo5n2u ucx/1.11.1/gcc-9.4.0-lktqyl4
    openmpi/4.1.1/gcc-9.4.0-epagguv
Changed directory to /rds/user/ar2217/hpc-work/L65/clrs-ls65.

JobID: 0
======
Time: Mon Feb 19 22:05:55 GMT 2024
Running on master node: gpu-q-1
Current directory: /rds/user/ar2217/hpc-work/L65/clrs-ls65

Nodes allocated:
================
gpu-q-1

numtasks=1, numnodes=1, mpi_tasks_per_node=1 (OMP_NUM_THREADS=1)

Executing command:
==================
python -m clrs.examples.run --checkpoint_path ./checkpoints/0 --processor_type mpnn_l2 --regularisation_weight 0.0 --checkpoint_path /tmp/CLRS30/0 --dataset_path /tmp/CLRS30/0 > logs/out.0

2024-02-19 22:06:02.652768: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-02-19 22:06:02.652935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-02-19 22:06:02.929622: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-02-19 22:06:06.739373: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
I0219 22:06:16.463372 22523184681088 xla_bridge.py:660] Unable to initialize backend 'cuda': Found cuSOLVER version 11200, but JAX was built against version 11401, which is newer. The copy of cuSOLVER that is installed must be at least as new as the version against which JAX was built.
I0219 22:06:16.486725 22523184681088 xla_bridge.py:660] Unable to initialize backend 'rocm': NOT_FOUND: Could not find registered platform with name: "rocm". Available platform names are: CUDA
I0219 22:06:16.494234 22523184681088 xla_bridge.py:660] Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: libtpu.so: cannot open shared object file: No such file or directory
W0219 22:06:16.494364 22523184681088 xla_bridge.py:724] CUDA backend failed to initialize: Found cuSOLVER version 11200, but JAX was built against version 11401, which is newer. The copy of cuSOLVER that is installed must be at least as new as the version against which JAX was built. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
I0219 22:06:17.422580 22523184681088 run.py:314] Creating samplers for algo bfs
W0219 22:06:17.423159 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
W0219 22:06:17.423433 22523184681088 samplers.py:100] Sampling dataset on-the-fly, unlimited samples.
W0219 22:06:17.622263 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
W0219 22:06:17.622500 22523184681088 samplers.py:100] Sampling dataset on-the-fly, unlimited samples.
W0219 22:06:17.842432 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
W0219 22:06:17.842671 22523184681088 samplers.py:100] Sampling dataset on-the-fly, unlimited samples.
W0219 22:06:18.113041 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
W0219 22:06:18.113282 22523184681088 samplers.py:100] Sampling dataset on-the-fly, unlimited samples.
W0219 22:06:18.423890 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
W0219 22:06:18.424152 22523184681088 samplers.py:100] Sampling dataset on-the-fly, unlimited samples.
W0219 22:06:18.792719 22523184681088 samplers.py:277] Ignoring kwargs {'length_needle'} when building sampler class <class 'clrs._src.samplers.BfsSampler'>
I0219 22:06:18.792973 22523184681088 samplers.py:112] Creating a dataset with 64 samples.
I0219 22:06:18.818313 22523184681088 run.py:173] Dataset not found in /tmp/CLRS30/0/CLRS30_v1.0.0. Downloading...
I0219 22:06:31.828992 22523184681088 dataset_info.py:482] Load dataset info from /tmp/CLRS30/0/CLRS30_v1.0.0/clrs_dataset/bfs_test/1.0.0
I0219 22:06:31.830756 22523184681088 dataset_info.py:482] Load dataset info from /tmp/CLRS30/0/CLRS30_v1.0.0/clrs_dataset/bfs_test/1.0.0
I0219 22:06:31.831261 22523184681088 dataset_builder.py:366] Reusing dataset clrs_dataset (/tmp/CLRS30/0/CLRS30_v1.0.0/clrs_dataset/bfs_test/1.0.0)
I0219 22:06:31.831350 22523184681088 logging_logger.py:44] Constructing tf.data.Dataset clrs_dataset for split test, from /tmp/CLRS30/0/CLRS30_v1.0.0/clrs_dataset/bfs_test/1.0.0
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147827050af0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478270b11d0; to 'JaxprTracer' at 0x1478270b1310>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147827032370>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147827118330>, in_tracers=(Traced<ShapedArray(float32[32,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,4,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[2,32,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[2,32,4,4]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[2,32,2,4,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,2,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,4,4,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[2,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478270426d0; dead>, <weakref at 0x147827042040; dead>, <weakref at 0x147827042270; dead>, <weakref at 0x147827042b30; to 'JaxprTracer' at 0x147827012f90>, <weakref at 0x1478270420e0; to 'JaxprTracer' at 0x1478270123b0>, <weakref at 0x1478270422c0; to 'JaxprTracer' at 0x147827012db0>, <weakref at 0x1478270428b0; to 'JaxprTracer' at 0x147827012bd0>], out_avals=[ShapedArray(float32[32,4,128]), ShapedArray(float32[32,4,4]), ShapedArray(float32[32,4]), ShapedArray(float32[]), ShapedArray(float32[32,4,4]), ShapedArray(float32[2,32,4,4]), ShapedArray(float32[2,32,4])], primitive=scan, params={'reverse': False, 'length': 2, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,4,1] b:f32[32,4,1] c:f32[32,4] d:f32[1,128] e:f32[256,128] f:f32[256,128]
    g:f32[32,4,4,1] h:f32[32,4,4,1] i:f32[32,4,4] j:f32[1,128] k:f32[128,128] l:f32[32,128]
    m:bool[32,4,4,128] n:f32[32,4,4,128] o:f32[384,128] p:f32[384,128] q:f32[128,128]
    r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128] v:f32[128,128] w:f32[128,1]
    x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128] bb:f32[1,128] bc:f32[128] bd:f32[1,128]
    be:f32[128] bf:f32[1,128] bg:f32[128] bh:f32[1,128] bi:f32[128] bj:f32[256,128]
    bk:f32[128] bl:f32[256,128] bm:f32[128] bn:f32[128,128] bo:f32[128] bp:f32[128,128]
    bq:f32[128] br:f32[384,128] bs:f32[128] bt:f32[384,128] bu:f32[128] bv:f32[128,128]
    bw:f32[128] bx:f32[128,1] by:f32[1] bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128]
    cd:f32[384,128] ce:f32[128] cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1]
    cj:f32[32,4,128] ck:f32[32,4,4] cl:f32[32,4] cm:f32[] cn:f32[32,4,4] co:f32[32,4,128]
    cp:f32[32,4] cq:bool[32,4] cr:f32[32,4,1] cs:f32[32,4,256] ct:f32[32,4,4] cu:f32[32,4,1]
    cv:f32[32,4,1] cw:bool[32,4,4] cx:f32[32,4,4,1] cy:f32[32,4,4,128] cz:f32[32,4,4,128]
    da:f32[32,4,128] db:f32[32,4,128] dc:f32[32,4,384] dd:f32[32,4,4,128] de:f32[32,4,4,128]
    df:f32[32,4,4,128] dg:f32[32,4,128] dh:i32[32,2,4,3] di:f32[32,2,4,128] dj:f32[32,4,128]
    dk:f32[32,4,128] dl:f32[2,32,4,128] dm:f32[2,32,4,128] dn:f32[32,4,128] do:f32[32,1,1]
    dp:f32[32,4,4,128] dq:f32[32,4,4,128] dr:f32[32,4,4,128] ds:f32[32,1,1]. let
    dt:f32[32,4,128] = mul cj co
    du:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] y
    dw:f32[32,4,128] = add du dv
    dx:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] ba
    dz:f32[32,4,128] = add dx dy
    ea:f32[32,4,128] = add dw dz
    eb:f32[32,4] = mul cl cp
    ec:f32[32,4] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,4] ee:bool[32,4] ef:f32[32,4]. let
          eg:f32[32,4] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,4,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 4, 1)
    ] ec
    ei:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,4,128] = add_any ei ej
    el:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] bg
    em:f32[32,4,128] = add ek el
    en:f32[32,4,128] = add ea em
    eo:f32[32,4,256] = concatenate[dimension=2] en cj
    ep:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,4,128] = add_any ep eq
    es:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] bk
    et:f32[32,4,128] = add er es
    eu:f32[32,1,4,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 4, 128)
    ] et
    ev:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,4,128] = add_any ev ew
    ey:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] bm
    ez:f32[32,4,128] = add ex ey
    fa:f32[32,4,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 4, 1, 128)
    ] ez
    fb:f32[32,4,4,128] = add eu fa
    fc:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] bc
    fe:f32[32,4,4,128] = add fc fd
    ff:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] be
    fh:f32[32,4,4,128] = add ff fg
    fi:f32[32,4,4,128] = add fe fh
    fj:f32[32,4,4] = mul ck ct
    fk:f32[32,4,4] = div fj cu
    fl:f32[32,4] = reduce_sum[axes=(2,)] fj
    fm:f32[32,4,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 4, 1)
    ] fl
    fn:f32[32,4,1] = neg fm
    fo:f32[32,4,4] = mul fn ct
    fp:f32[32,4,4] = mul fo cv
    fq:f32[32,4,4] = add_any fk fp
    fr:f32[32,4,4] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,4,4] ft:bool[32,4,4] fu:f32[32,4,4]. let
          fv:f32[32,4,4] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,4,4,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 4, 4, 1)
    ] fr
    fx:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,4,4,128] = add_any fx fy
    ga:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] bi
    gb:f32[32,4,4,128] = add fz ga
    gc:f32[32,4,4,128] = add fi gb
    gd:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,4,4,128] = add_any gd ge
    gg:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] bo
    gh:f32[32,4,4,128] = add gf gg
    gi:f32[32,4,4,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,4,4,128] = add gi gm
    go:f32[32,4,4,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,4,4,128] gq:bool[32,4,4,128] gr:f32[32,4,4,128]. let
          gs:f32[32,4,4,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,4,4,128] = mul go cz
    gu:f32[32,4,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,4,128] = div gu da
    gw:f32[32,4,128] = mul gv db
    gx:f32[32,4,128] = add_any dt gw
    gy:f32[32,4,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,4,128] = add_any gz ha
    hc:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] cc
    hd:f32[32,4,128] = add hb hc
    he:f32[32,4,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 4, 1, 128)
    ] hd
    hf:f32[32,4,4,128] = mul he dd
    hg:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,4,128] = add_any hg hh
    hj:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] ce
    hk:f32[32,4,128] = add hi hj
    hl:f32[32,4,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 4, 1, 128)
    ] hk
    hm:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,4,4,128] = add_any hm hn
    hp:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] cg
    hq:f32[32,4,4,128] = add ho hp
    hr:f32[32,4,4,128] = add hl hq
    hs:f32[32,4,4,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,4,4,128] = mul hs de
    hu:f32[32,4,4,128] = add_any hf ht
    hv:f32[32,4,4,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,4,4,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,4,4,1] = add_any hv hw
    hy:f32[32,4,4,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 1)
    ] ci
    hz:f32[32,4,4,1] = add hx hy
    ia:f32[32,4,4] = squeeze[dimensions=(3,)] hz
    ib:f32[32,4,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,4,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,4,1] = add_any ib ic
    ie:f32[32,4,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 1)
    ] ca
    if:f32[32,4,1] = add id ie
    ig:f32[32,4] = squeeze[dimensions=(2,)] if
    ih:f32[32,4,128] = mul cj dg
    ii:f32[32,2,4,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,4,4,128] ik:i32[32,2,4,3]. let
          il:f32[32,2,4,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,4,128] = mul ii di
    in:f32[32,4,128] = reduce_sum[axes=(1,)] im
    io:f32[32,4,128] = div in dj
    ip:f32[32,4,128] = mul io dk
    iq:f32[32,4,128] = add_any ih ip
    ir:f32[2,32,4,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,4,128] = scan[
      jaxpr={ lambda ; it:f32[32,4,128] iu:f32[32,4,128] iv:f32[32,4,128] iw:f32[32,4,128]. let
          ix:f32[32,4,128] = mul it iv
          iy:f32[32,4,128] = mul iu iw
          iz:f32[32,4,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,4,128] = sub iq is
    jb:f32[32,4,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 16384.0
    je:f32[] = add jd cm
    jf:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,4,128] = add_any jf jg
    ji:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] bs
    jj:f32[32,4,128] = add jh ji
    jk:f32[32,4,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 4, 1, 128)
    ] jj
    jl:f32[32,4,4,128] = mul jk dp
    jm:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,4,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,4,128] = add_any jm jn
    jp:f32[32,4,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 4, 128)
    ] bu
    jq:f32[32,4,128] = add jo jp
    jr:f32[32,4,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 4, 1, 128)
    ] jq
    js:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,4,4,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,4,4,128] = add_any js jt
    jv:f32[32,4,4,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 128)
    ] bw
    jw:f32[32,4,4,128] = add ju jv
    jx:f32[32,4,4,128] = add jr jw
    jy:f32[32,4,4,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,4,4,128] = mul jy dq
    ka:f32[32,4,4,128] = add_any jl jz
    kb:f32[32,4,4,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,4,4,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,4,4,1] = add_any kb kc
    ke:f32[32,4,4,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 4, 4, 1)
    ] by
    kf:f32[32,4,4,1] = add kd ke
    kg:f32[32,4,4] = squeeze[dimensions=(3,)] kf
    kh:f32[32,4,4] = mul do kg
    ki:f32[32,4,4] = mul ds cn
    kj:f32[32,4,4] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147826f2d7f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147827050990>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x14782709cc70; to 'JaxprTracer' at 0x14782709cc20>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147826eea170>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:06:42.341183 22523184681088 run.py:488] Algo bfs step 0 current loss 2.806006, current_train_items 32.
I0219 22:06:42.902795 22523184681088 run.py:508] (val) algo bfs step 0: {'pi': 0.595703125, 'score': 0.595703125, 'examples_seen': 32, 'step': 0, 'algorithm': 'bfs'}
I0219 22:06:42.903042 22523184681088 run.py:524] Checkpointing best model, best avg val score was -1.000, current avg val score is 0.596, val scores are: bfs: 0.596
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147826ad0fe0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827d60090; to 'JaxprTracer' at 0x147827d602c0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147827e18430>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478270b7470>, in_tracers=(Traced<ShapedArray(float32[32,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,7,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[4,32,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[4,32,7,7]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[4,32,2,7,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,2,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,2,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,2,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,7,7,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[4,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827e440e0; dead>, <weakref at 0x147827e44270; dead>, <weakref at 0x147827e44220; dead>, <weakref at 0x147827e44360; to 'JaxprTracer' at 0x147827e44a40>, <weakref at 0x147827e44090; to 'JaxprTracer' at 0x147827e44c20>, <weakref at 0x147827e442c0; to 'JaxprTracer' at 0x147827e44db0>, <weakref at 0x147827e44310; to 'JaxprTracer' at 0x147827e441d0>], out_avals=[ShapedArray(float32[32,7,128]), ShapedArray(float32[32,7,7]), ShapedArray(float32[32,7]), ShapedArray(float32[]), ShapedArray(float32[32,7,7]), ShapedArray(float32[4,32,7,7]), ShapedArray(float32[4,32,7])], primitive=scan, params={'reverse': False, 'length': 4, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,7,1] b:f32[32,7,1] c:f32[32,7] d:f32[1,128] e:f32[256,128] f:f32[256,128]
    g:f32[32,7,7,1] h:f32[32,7,7,1] i:f32[32,7,7] j:f32[1,128] k:f32[128,128] l:f32[32,128]
    m:bool[32,7,7,128] n:f32[32,7,7,128] o:f32[384,128] p:f32[384,128] q:f32[128,128]
    r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128] v:f32[128,128] w:f32[128,1]
    x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128] bb:f32[1,128] bc:f32[128] bd:f32[1,128]
    be:f32[128] bf:f32[1,128] bg:f32[128] bh:f32[1,128] bi:f32[128] bj:f32[256,128]
    bk:f32[128] bl:f32[256,128] bm:f32[128] bn:f32[128,128] bo:f32[128] bp:f32[128,128]
    bq:f32[128] br:f32[384,128] bs:f32[128] bt:f32[384,128] bu:f32[128] bv:f32[128,128]
    bw:f32[128] bx:f32[128,1] by:f32[1] bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128]
    cd:f32[384,128] ce:f32[128] cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1]
    cj:f32[32,7,128] ck:f32[32,7,7] cl:f32[32,7] cm:f32[] cn:f32[32,7,7] co:f32[32,7,128]
    cp:f32[32,7] cq:bool[32,7] cr:f32[32,7,1] cs:f32[32,7,256] ct:f32[32,7,7] cu:f32[32,7,1]
    cv:f32[32,7,1] cw:bool[32,7,7] cx:f32[32,7,7,1] cy:f32[32,7,7,128] cz:f32[32,7,7,128]
    da:f32[32,7,128] db:f32[32,7,128] dc:f32[32,7,384] dd:f32[32,7,7,128] de:f32[32,7,7,128]
    df:f32[32,7,7,128] dg:f32[32,7,128] dh:i32[32,2,7,3] di:f32[32,2,7,128] dj:f32[32,7,128]
    dk:f32[32,7,128] dl:f32[2,32,7,128] dm:f32[2,32,7,128] dn:f32[32,7,128] do:f32[32,1,1]
    dp:f32[32,7,7,128] dq:f32[32,7,7,128] dr:f32[32,7,7,128] ds:f32[32,1,1]. let
    dt:f32[32,7,128] = mul cj co
    du:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] y
    dw:f32[32,7,128] = add du dv
    dx:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] ba
    dz:f32[32,7,128] = add dx dy
    ea:f32[32,7,128] = add dw dz
    eb:f32[32,7] = mul cl cp
    ec:f32[32,7] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,7] ee:bool[32,7] ef:f32[32,7]. let
          eg:f32[32,7] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,7,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 7, 1)
    ] ec
    ei:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,7,128] = add_any ei ej
    el:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] bg
    em:f32[32,7,128] = add ek el
    en:f32[32,7,128] = add ea em
    eo:f32[32,7,256] = concatenate[dimension=2] en cj
    ep:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,7,128] = add_any ep eq
    es:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] bk
    et:f32[32,7,128] = add er es
    eu:f32[32,1,7,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 7, 128)
    ] et
    ev:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,7,128] = add_any ev ew
    ey:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] bm
    ez:f32[32,7,128] = add ex ey
    fa:f32[32,7,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 7, 1, 128)
    ] ez
    fb:f32[32,7,7,128] = add eu fa
    fc:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] bc
    fe:f32[32,7,7,128] = add fc fd
    ff:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] be
    fh:f32[32,7,7,128] = add ff fg
    fi:f32[32,7,7,128] = add fe fh
    fj:f32[32,7,7] = mul ck ct
    fk:f32[32,7,7] = div fj cu
    fl:f32[32,7] = reduce_sum[axes=(2,)] fj
    fm:f32[32,7,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 7, 1)
    ] fl
    fn:f32[32,7,1] = neg fm
    fo:f32[32,7,7] = mul fn ct
    fp:f32[32,7,7] = mul fo cv
    fq:f32[32,7,7] = add_any fk fp
    fr:f32[32,7,7] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,7,7] ft:bool[32,7,7] fu:f32[32,7,7]. let
          fv:f32[32,7,7] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,7,7,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 7, 7, 1)
    ] fr
    fx:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,7,7,128] = add_any fx fy
    ga:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] bi
    gb:f32[32,7,7,128] = add fz ga
    gc:f32[32,7,7,128] = add fi gb
    gd:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,7,7,128] = add_any gd ge
    gg:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] bo
    gh:f32[32,7,7,128] = add gf gg
    gi:f32[32,7,7,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,7,7,128] = add gi gm
    go:f32[32,7,7,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,7,7,128] gq:bool[32,7,7,128] gr:f32[32,7,7,128]. let
          gs:f32[32,7,7,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,7,7,128] = mul go cz
    gu:f32[32,7,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,7,128] = div gu da
    gw:f32[32,7,128] = mul gv db
    gx:f32[32,7,128] = add_any dt gw
    gy:f32[32,7,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,7,128] = add_any gz ha
    hc:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] cc
    hd:f32[32,7,128] = add hb hc
    he:f32[32,7,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 7, 1, 128)
    ] hd
    hf:f32[32,7,7,128] = mul he dd
    hg:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,7,128] = add_any hg hh
    hj:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] ce
    hk:f32[32,7,128] = add hi hj
    hl:f32[32,7,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 7, 1, 128)
    ] hk
    hm:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,7,7,128] = add_any hm hn
    hp:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] cg
    hq:f32[32,7,7,128] = add ho hp
    hr:f32[32,7,7,128] = add hl hq
    hs:f32[32,7,7,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,7,7,128] = mul hs de
    hu:f32[32,7,7,128] = add_any hf ht
    hv:f32[32,7,7,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,7,7,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,7,7,1] = add_any hv hw
    hy:f32[32,7,7,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 1)
    ] ci
    hz:f32[32,7,7,1] = add hx hy
    ia:f32[32,7,7] = squeeze[dimensions=(3,)] hz
    ib:f32[32,7,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,7,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,7,1] = add_any ib ic
    ie:f32[32,7,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 1)
    ] ca
    if:f32[32,7,1] = add id ie
    ig:f32[32,7] = squeeze[dimensions=(2,)] if
    ih:f32[32,7,128] = mul cj dg
    ii:f32[32,2,7,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,7,7,128] ik:i32[32,2,7,3]. let
          il:f32[32,2,7,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,7,128] = mul ii di
    in:f32[32,7,128] = reduce_sum[axes=(1,)] im
    io:f32[32,7,128] = div in dj
    ip:f32[32,7,128] = mul io dk
    iq:f32[32,7,128] = add_any ih ip
    ir:f32[2,32,7,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,7,128] = scan[
      jaxpr={ lambda ; it:f32[32,7,128] iu:f32[32,7,128] iv:f32[32,7,128] iw:f32[32,7,128]. let
          ix:f32[32,7,128] = mul it iv
          iy:f32[32,7,128] = mul iu iw
          iz:f32[32,7,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,7,128] = sub iq is
    jb:f32[32,7,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 28672.0
    je:f32[] = add jd cm
    jf:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,7,128] = add_any jf jg
    ji:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] bs
    jj:f32[32,7,128] = add jh ji
    jk:f32[32,7,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 7, 1, 128)
    ] jj
    jl:f32[32,7,7,128] = mul jk dp
    jm:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,7,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,7,128] = add_any jm jn
    jp:f32[32,7,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 7, 128)
    ] bu
    jq:f32[32,7,128] = add jo jp
    jr:f32[32,7,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 7, 1, 128)
    ] jq
    js:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,7,7,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,7,7,128] = add_any js jt
    jv:f32[32,7,7,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 128)
    ] bw
    jw:f32[32,7,7,128] = add ju jv
    jx:f32[32,7,7,128] = add jr jw
    jy:f32[32,7,7,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,7,7,128] = mul jy dq
    ka:f32[32,7,7,128] = add_any jl jz
    kb:f32[32,7,7,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,7,7,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,7,7,1] = add_any kb kc
    ke:f32[32,7,7,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 7, 7, 1)
    ] by
    kf:f32[32,7,7,1] = add kd ke
    kg:f32[32,7,7] = squeeze[dimensions=(3,)] kf
    kh:f32[32,7,7] = mul do kg
    ki:f32[32,7,7] = mul ds cn
    kj:f32[32,7,7] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147827e2d570>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147826ad0ee0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827d60a40; to 'JaxprTracer' at 0x147827d607c0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147827d41870>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:06:49.888751 22523184681088 run.py:488] Algo bfs step 1 current loss 2.388057, current_train_items 64.
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478251d3c50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478252fa4a0; to 'JaxprTracer' at 0x1478252fa270>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478252eba30>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147826eb7060>, in_tracers=(Traced<ShapedArray(float32[32,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,11,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[7,32,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[7,32,11,11]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[7,32,2,11,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,2,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,2,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,2,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,11,11,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x14782523abd0; dead>, <weakref at 0x14782523a9f0; dead>, <weakref at 0x14782523ac70; dead>, <weakref at 0x14782523a680; to 'JaxprTracer' at 0x14782523a180>, <weakref at 0x14782523a450; to 'JaxprTracer' at 0x14782523a310>, <weakref at 0x14782523a400; to 'JaxprTracer' at 0x14782523a630>, <weakref at 0x14782523a2c0; to 'JaxprTracer' at 0x14782523a7c0>], out_avals=[ShapedArray(float32[32,11,128]), ShapedArray(float32[32,11,11]), ShapedArray(float32[32,11]), ShapedArray(float32[]), ShapedArray(float32[32,11,11]), ShapedArray(float32[7,32,11,11]), ShapedArray(float32[7,32,11])], primitive=scan, params={'reverse': False, 'length': 7, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,11,1] b:f32[32,11,1] c:f32[32,11] d:f32[1,128] e:f32[256,128]
    f:f32[256,128] g:f32[32,11,11,1] h:f32[32,11,11,1] i:f32[32,11,11] j:f32[1,128]
    k:f32[128,128] l:f32[32,128] m:bool[32,11,11,128] n:f32[32,11,11,128] o:f32[384,128]
    p:f32[384,128] q:f32[128,128] r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128]
    v:f32[128,128] w:f32[128,1] x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128]
    bb:f32[1,128] bc:f32[128] bd:f32[1,128] be:f32[128] bf:f32[1,128] bg:f32[128]
    bh:f32[1,128] bi:f32[128] bj:f32[256,128] bk:f32[128] bl:f32[256,128] bm:f32[128]
    bn:f32[128,128] bo:f32[128] bp:f32[128,128] bq:f32[128] br:f32[384,128] bs:f32[128]
    bt:f32[384,128] bu:f32[128] bv:f32[128,128] bw:f32[128] bx:f32[128,1] by:f32[1]
    bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128] cd:f32[384,128] ce:f32[128]
    cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1] cj:f32[32,11,128] ck:f32[32,11,11]
    cl:f32[32,11] cm:f32[] cn:f32[32,11,11] co:f32[32,11,128] cp:f32[32,11] cq:bool[32,11]
    cr:f32[32,11,1] cs:f32[32,11,256] ct:f32[32,11,11] cu:f32[32,11,1] cv:f32[32,11,1]
    cw:bool[32,11,11] cx:f32[32,11,11,1] cy:f32[32,11,11,128] cz:f32[32,11,11,128]
    da:f32[32,11,128] db:f32[32,11,128] dc:f32[32,11,384] dd:f32[32,11,11,128] de:f32[32,11,11,128]
    df:f32[32,11,11,128] dg:f32[32,11,128] dh:i32[32,2,11,3] di:f32[32,2,11,128]
    dj:f32[32,11,128] dk:f32[32,11,128] dl:f32[2,32,11,128] dm:f32[2,32,11,128] dn:f32[32,11,128]
    do:f32[32,1,1] dp:f32[32,11,11,128] dq:f32[32,11,11,128] dr:f32[32,11,11,128]
    ds:f32[32,1,1]. let
    dt:f32[32,11,128] = mul cj co
    du:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] y
    dw:f32[32,11,128] = add du dv
    dx:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] ba
    dz:f32[32,11,128] = add dx dy
    ea:f32[32,11,128] = add dw dz
    eb:f32[32,11] = mul cl cp
    ec:f32[32,11] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,11] ee:bool[32,11] ef:f32[32,11]. let
          eg:f32[32,11] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,11,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 11, 1)
    ] ec
    ei:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,11,128] = add_any ei ej
    el:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] bg
    em:f32[32,11,128] = add ek el
    en:f32[32,11,128] = add ea em
    eo:f32[32,11,256] = concatenate[dimension=2] en cj
    ep:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,11,128] = add_any ep eq
    es:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] bk
    et:f32[32,11,128] = add er es
    eu:f32[32,1,11,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 11, 128)
    ] et
    ev:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,11,128] = add_any ev ew
    ey:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] bm
    ez:f32[32,11,128] = add ex ey
    fa:f32[32,11,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 11, 1, 128)
    ] ez
    fb:f32[32,11,11,128] = add eu fa
    fc:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] bc
    fe:f32[32,11,11,128] = add fc fd
    ff:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] be
    fh:f32[32,11,11,128] = add ff fg
    fi:f32[32,11,11,128] = add fe fh
    fj:f32[32,11,11] = mul ck ct
    fk:f32[32,11,11] = div fj cu
    fl:f32[32,11] = reduce_sum[axes=(2,)] fj
    fm:f32[32,11,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 11, 1)
    ] fl
    fn:f32[32,11,1] = neg fm
    fo:f32[32,11,11] = mul fn ct
    fp:f32[32,11,11] = mul fo cv
    fq:f32[32,11,11] = add_any fk fp
    fr:f32[32,11,11] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,11,11] ft:bool[32,11,11] fu:f32[32,11,11]. let
          fv:f32[32,11,11] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,11,11,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 11, 11, 1)
    ] fr
    fx:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,11,11,128] = add_any fx fy
    ga:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] bi
    gb:f32[32,11,11,128] = add fz ga
    gc:f32[32,11,11,128] = add fi gb
    gd:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,11,11,128] = add_any gd ge
    gg:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] bo
    gh:f32[32,11,11,128] = add gf gg
    gi:f32[32,11,11,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,11,11,128] = add gi gm
    go:f32[32,11,11,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,11,11,128] gq:bool[32,11,11,128] gr:f32[32,11,11,128]. let
          gs:f32[32,11,11,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,11,11,128] = mul go cz
    gu:f32[32,11,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,11,128] = div gu da
    gw:f32[32,11,128] = mul gv db
    gx:f32[32,11,128] = add_any dt gw
    gy:f32[32,11,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,11,128] = add_any gz ha
    hc:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] cc
    hd:f32[32,11,128] = add hb hc
    he:f32[32,11,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 11, 1, 128)
    ] hd
    hf:f32[32,11,11,128] = mul he dd
    hg:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,11,128] = add_any hg hh
    hj:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] ce
    hk:f32[32,11,128] = add hi hj
    hl:f32[32,11,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 11, 1, 128)
    ] hk
    hm:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,11,11,128] = add_any hm hn
    hp:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] cg
    hq:f32[32,11,11,128] = add ho hp
    hr:f32[32,11,11,128] = add hl hq
    hs:f32[32,11,11,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,11,11,128] = mul hs de
    hu:f32[32,11,11,128] = add_any hf ht
    hv:f32[32,11,11,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,11,11,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,11,11,1] = add_any hv hw
    hy:f32[32,11,11,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 1)
    ] ci
    hz:f32[32,11,11,1] = add hx hy
    ia:f32[32,11,11] = squeeze[dimensions=(3,)] hz
    ib:f32[32,11,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,11,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,11,1] = add_any ib ic
    ie:f32[32,11,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 1)
    ] ca
    if:f32[32,11,1] = add id ie
    ig:f32[32,11] = squeeze[dimensions=(2,)] if
    ih:f32[32,11,128] = mul cj dg
    ii:f32[32,2,11,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,11,11,128] ik:i32[32,2,11,3]. let
          il:f32[32,2,11,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,11,128] = mul ii di
    in:f32[32,11,128] = reduce_sum[axes=(1,)] im
    io:f32[32,11,128] = div in dj
    ip:f32[32,11,128] = mul io dk
    iq:f32[32,11,128] = add_any ih ip
    ir:f32[2,32,11,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,11,128] = scan[
      jaxpr={ lambda ; it:f32[32,11,128] iu:f32[32,11,128] iv:f32[32,11,128] iw:f32[32,11,128]. let
          ix:f32[32,11,128] = mul it iv
          iy:f32[32,11,128] = mul iu iw
          iz:f32[32,11,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,11,128] = sub iq is
    jb:f32[32,11,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 45056.0
    je:f32[] = add jd cm
    jf:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,11,128] = add_any jf jg
    ji:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] bs
    jj:f32[32,11,128] = add jh ji
    jk:f32[32,11,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 11, 1, 128)
    ] jj
    jl:f32[32,11,11,128] = mul jk dp
    jm:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,11,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,11,128] = add_any jm jn
    jp:f32[32,11,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 11, 128)
    ] bu
    jq:f32[32,11,128] = add jo jp
    jr:f32[32,11,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 11, 1, 128)
    ] jq
    js:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,11,11,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,11,11,128] = add_any js jt
    jv:f32[32,11,11,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 128)
    ] bw
    jw:f32[32,11,11,128] = add ju jv
    jx:f32[32,11,11,128] = add jr jw
    jy:f32[32,11,11,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,11,11,128] = mul jy dq
    ka:f32[32,11,11,128] = add_any jl jz
    kb:f32[32,11,11,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,11,11,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,11,11,1] = add_any kb kc
    ke:f32[32,11,11,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 11, 11, 1)
    ] by
    kf:f32[32,11,11,1] = add kd ke
    kg:f32[32,11,11] = squeeze[dimensions=(3,)] kf
    kh:f32[32,11,11] = mul do kg
    ki:f32[32,11,11] = mul ds cn
    kj:f32[32,11,11] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147825362c30>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478251d3b50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478252fa0e0; to 'JaxprTracer' at 0x1478252fa360>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478251c7130>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:06:57.081550 22523184681088 run.py:488] Algo bfs step 2 current loss 2.129044, current_train_items 96.
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478ac4beb50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827d8c5e0; to 'JaxprTracer' at 0x147827d8ce00>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac4e8f30>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147826bf3200>, in_tracers=(Traced<ShapedArray(float32[32,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,13,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[8,32,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[8,32,13,13]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[8,32,2,13,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,2,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,2,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,2,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,13,13,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827927c20; dead>, <weakref at 0x147827927590; dead>, <weakref at 0x147827927ea0; dead>, <weakref at 0x147827058ae0; to 'JaxprTracer' at 0x147827927b80>, <weakref at 0x147827058f90; to 'JaxprTracer' at 0x147827927db0>, <weakref at 0x1478270586d0; to 'JaxprTracer' at 0x147827927cc0>, <weakref at 0x1478270581d0; to 'JaxprTracer' at 0x1478279279f0>], out_avals=[ShapedArray(float32[32,13,128]), ShapedArray(float32[32,13,13]), ShapedArray(float32[32,13]), ShapedArray(float32[]), ShapedArray(float32[32,13,13]), ShapedArray(float32[8,32,13,13]), ShapedArray(float32[8,32,13])], primitive=scan, params={'reverse': False, 'length': 8, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,13,1] b:f32[32,13,1] c:f32[32,13] d:f32[1,128] e:f32[256,128]
    f:f32[256,128] g:f32[32,13,13,1] h:f32[32,13,13,1] i:f32[32,13,13] j:f32[1,128]
    k:f32[128,128] l:f32[32,128] m:bool[32,13,13,128] n:f32[32,13,13,128] o:f32[384,128]
    p:f32[384,128] q:f32[128,128] r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128]
    v:f32[128,128] w:f32[128,1] x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128]
    bb:f32[1,128] bc:f32[128] bd:f32[1,128] be:f32[128] bf:f32[1,128] bg:f32[128]
    bh:f32[1,128] bi:f32[128] bj:f32[256,128] bk:f32[128] bl:f32[256,128] bm:f32[128]
    bn:f32[128,128] bo:f32[128] bp:f32[128,128] bq:f32[128] br:f32[384,128] bs:f32[128]
    bt:f32[384,128] bu:f32[128] bv:f32[128,128] bw:f32[128] bx:f32[128,1] by:f32[1]
    bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128] cd:f32[384,128] ce:f32[128]
    cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1] cj:f32[32,13,128] ck:f32[32,13,13]
    cl:f32[32,13] cm:f32[] cn:f32[32,13,13] co:f32[32,13,128] cp:f32[32,13] cq:bool[32,13]
    cr:f32[32,13,1] cs:f32[32,13,256] ct:f32[32,13,13] cu:f32[32,13,1] cv:f32[32,13,1]
    cw:bool[32,13,13] cx:f32[32,13,13,1] cy:f32[32,13,13,128] cz:f32[32,13,13,128]
    da:f32[32,13,128] db:f32[32,13,128] dc:f32[32,13,384] dd:f32[32,13,13,128] de:f32[32,13,13,128]
    df:f32[32,13,13,128] dg:f32[32,13,128] dh:i32[32,2,13,3] di:f32[32,2,13,128]
    dj:f32[32,13,128] dk:f32[32,13,128] dl:f32[2,32,13,128] dm:f32[2,32,13,128] dn:f32[32,13,128]
    do:f32[32,1,1] dp:f32[32,13,13,128] dq:f32[32,13,13,128] dr:f32[32,13,13,128]
    ds:f32[32,1,1]. let
    dt:f32[32,13,128] = mul cj co
    du:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] y
    dw:f32[32,13,128] = add du dv
    dx:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] ba
    dz:f32[32,13,128] = add dx dy
    ea:f32[32,13,128] = add dw dz
    eb:f32[32,13] = mul cl cp
    ec:f32[32,13] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,13] ee:bool[32,13] ef:f32[32,13]. let
          eg:f32[32,13] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,13,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 13, 1)
    ] ec
    ei:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,13,128] = add_any ei ej
    el:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] bg
    em:f32[32,13,128] = add ek el
    en:f32[32,13,128] = add ea em
    eo:f32[32,13,256] = concatenate[dimension=2] en cj
    ep:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,13,128] = add_any ep eq
    es:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] bk
    et:f32[32,13,128] = add er es
    eu:f32[32,1,13,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 13, 128)
    ] et
    ev:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,13,128] = add_any ev ew
    ey:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] bm
    ez:f32[32,13,128] = add ex ey
    fa:f32[32,13,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 13, 1, 128)
    ] ez
    fb:f32[32,13,13,128] = add eu fa
    fc:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] bc
    fe:f32[32,13,13,128] = add fc fd
    ff:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] be
    fh:f32[32,13,13,128] = add ff fg
    fi:f32[32,13,13,128] = add fe fh
    fj:f32[32,13,13] = mul ck ct
    fk:f32[32,13,13] = div fj cu
    fl:f32[32,13] = reduce_sum[axes=(2,)] fj
    fm:f32[32,13,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 13, 1)
    ] fl
    fn:f32[32,13,1] = neg fm
    fo:f32[32,13,13] = mul fn ct
    fp:f32[32,13,13] = mul fo cv
    fq:f32[32,13,13] = add_any fk fp
    fr:f32[32,13,13] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,13,13] ft:bool[32,13,13] fu:f32[32,13,13]. let
          fv:f32[32,13,13] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,13,13,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 13, 13, 1)
    ] fr
    fx:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,13,13,128] = add_any fx fy
    ga:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] bi
    gb:f32[32,13,13,128] = add fz ga
    gc:f32[32,13,13,128] = add fi gb
    gd:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,13,13,128] = add_any gd ge
    gg:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] bo
    gh:f32[32,13,13,128] = add gf gg
    gi:f32[32,13,13,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,13,13,128] = add gi gm
    go:f32[32,13,13,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,13,13,128] gq:bool[32,13,13,128] gr:f32[32,13,13,128]. let
          gs:f32[32,13,13,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,13,13,128] = mul go cz
    gu:f32[32,13,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,13,128] = div gu da
    gw:f32[32,13,128] = mul gv db
    gx:f32[32,13,128] = add_any dt gw
    gy:f32[32,13,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,13,128] = add_any gz ha
    hc:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] cc
    hd:f32[32,13,128] = add hb hc
    he:f32[32,13,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 13, 1, 128)
    ] hd
    hf:f32[32,13,13,128] = mul he dd
    hg:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,13,128] = add_any hg hh
    hj:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] ce
    hk:f32[32,13,128] = add hi hj
    hl:f32[32,13,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 13, 1, 128)
    ] hk
    hm:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,13,13,128] = add_any hm hn
    hp:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] cg
    hq:f32[32,13,13,128] = add ho hp
    hr:f32[32,13,13,128] = add hl hq
    hs:f32[32,13,13,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,13,13,128] = mul hs de
    hu:f32[32,13,13,128] = add_any hf ht
    hv:f32[32,13,13,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,13,13,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,13,13,1] = add_any hv hw
    hy:f32[32,13,13,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 1)
    ] ci
    hz:f32[32,13,13,1] = add hx hy
    ia:f32[32,13,13] = squeeze[dimensions=(3,)] hz
    ib:f32[32,13,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,13,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,13,1] = add_any ib ic
    ie:f32[32,13,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 1)
    ] ca
    if:f32[32,13,1] = add id ie
    ig:f32[32,13] = squeeze[dimensions=(2,)] if
    ih:f32[32,13,128] = mul cj dg
    ii:f32[32,2,13,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,13,13,128] ik:i32[32,2,13,3]. let
          il:f32[32,2,13,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,13,128] = mul ii di
    in:f32[32,13,128] = reduce_sum[axes=(1,)] im
    io:f32[32,13,128] = div in dj
    ip:f32[32,13,128] = mul io dk
    iq:f32[32,13,128] = add_any ih ip
    ir:f32[2,32,13,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,13,128] = scan[
      jaxpr={ lambda ; it:f32[32,13,128] iu:f32[32,13,128] iv:f32[32,13,128] iw:f32[32,13,128]. let
          ix:f32[32,13,128] = mul it iv
          iy:f32[32,13,128] = mul iu iw
          iz:f32[32,13,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,13,128] = sub iq is
    jb:f32[32,13,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 53248.0
    je:f32[] = add jd cm
    jf:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,13,128] = add_any jf jg
    ji:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] bs
    jj:f32[32,13,128] = add jh ji
    jk:f32[32,13,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 13, 1, 128)
    ] jj
    jl:f32[32,13,13,128] = mul jk dp
    jm:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,13,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,13,128] = add_any jm jn
    jp:f32[32,13,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 13, 128)
    ] bu
    jq:f32[32,13,128] = add jo jp
    jr:f32[32,13,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 13, 1, 128)
    ] jq
    js:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,13,13,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,13,13,128] = add_any js jt
    jv:f32[32,13,13,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 128)
    ] bw
    jw:f32[32,13,13,128] = add ju jv
    jx:f32[32,13,13,128] = add jr jw
    jy:f32[32,13,13,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,13,13,128] = mul jy dq
    ka:f32[32,13,13,128] = add_any jl jz
    kb:f32[32,13,13,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,13,13,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,13,13,1] = add_any kb kc
    ke:f32[32,13,13,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 13, 13, 1)
    ] by
    kf:f32[32,13,13,1] = add kd ke
    kg:f32[32,13,13] = squeeze[dimensions=(3,)] kf
    kh:f32[32,13,13] = mul do kg
    ki:f32[32,13,13] = mul ds cn
    kj:f32[32,13,13] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac48c2f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478ac4bea50>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827d8c8b0; to 'JaxprTracer' at 0x147827d8cd60>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac55e470>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:07:04.297795 22523184681088 run.py:488] Algo bfs step 3 current loss 2.151893, current_train_items 128.
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147824c20fb0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147824cc4900; to 'JaxprTracer' at 0x147824cc47c0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147824db4030>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147826eb7340>, in_tracers=(Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[7,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[7,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[7,32,2,16,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,2,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[7,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147824d554a0; dead>, <weakref at 0x147824d55b80; dead>, <weakref at 0x147824d55770; dead>, <weakref at 0x147824d551d0; to 'JaxprTracer' at 0x147824d55450>, <weakref at 0x147824d55310; to 'JaxprTracer' at 0x147824d55630>, <weakref at 0x147824d554f0; to 'JaxprTracer' at 0x147824d55bd0>, <weakref at 0x147824d55360; to 'JaxprTracer' at 0x147824d55d10>], out_avals=[ShapedArray(float32[32,16,128]), ShapedArray(float32[32,16,16]), ShapedArray(float32[32,16]), ShapedArray(float32[]), ShapedArray(float32[32,16,16]), ShapedArray(float32[7,32,16,16]), ShapedArray(float32[7,32,16])], primitive=scan, params={'reverse': False, 'length': 7, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,16,1] b:f32[32,16,1] c:f32[32,16] d:f32[1,128] e:f32[256,128]
    f:f32[256,128] g:f32[32,16,16,1] h:f32[32,16,16,1] i:f32[32,16,16] j:f32[1,128]
    k:f32[128,128] l:f32[32,128] m:bool[32,16,16,128] n:f32[32,16,16,128] o:f32[384,128]
    p:f32[384,128] q:f32[128,128] r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128]
    v:f32[128,128] w:f32[128,1] x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128]
    bb:f32[1,128] bc:f32[128] bd:f32[1,128] be:f32[128] bf:f32[1,128] bg:f32[128]
    bh:f32[1,128] bi:f32[128] bj:f32[256,128] bk:f32[128] bl:f32[256,128] bm:f32[128]
    bn:f32[128,128] bo:f32[128] bp:f32[128,128] bq:f32[128] br:f32[384,128] bs:f32[128]
    bt:f32[384,128] bu:f32[128] bv:f32[128,128] bw:f32[128] bx:f32[128,1] by:f32[1]
    bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128] cd:f32[384,128] ce:f32[128]
    cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1] cj:f32[32,16,128] ck:f32[32,16,16]
    cl:f32[32,16] cm:f32[] cn:f32[32,16,16] co:f32[32,16,128] cp:f32[32,16] cq:bool[32,16]
    cr:f32[32,16,1] cs:f32[32,16,256] ct:f32[32,16,16] cu:f32[32,16,1] cv:f32[32,16,1]
    cw:bool[32,16,16] cx:f32[32,16,16,1] cy:f32[32,16,16,128] cz:f32[32,16,16,128]
    da:f32[32,16,128] db:f32[32,16,128] dc:f32[32,16,384] dd:f32[32,16,16,128] de:f32[32,16,16,128]
    df:f32[32,16,16,128] dg:f32[32,16,128] dh:i32[32,2,16,3] di:f32[32,2,16,128]
    dj:f32[32,16,128] dk:f32[32,16,128] dl:f32[2,32,16,128] dm:f32[2,32,16,128] dn:f32[32,16,128]
    do:f32[32,1,1] dp:f32[32,16,16,128] dq:f32[32,16,16,128] dr:f32[32,16,16,128]
    ds:f32[32,1,1]. let
    dt:f32[32,16,128] = mul cj co
    du:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] y
    dw:f32[32,16,128] = add du dv
    dx:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ba
    dz:f32[32,16,128] = add dx dy
    ea:f32[32,16,128] = add dw dz
    eb:f32[32,16] = mul cl cp
    ec:f32[32,16] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,16] ee:bool[32,16] ef:f32[32,16]. let
          eg:f32[32,16] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] ec
    ei:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,16,128] = add_any ei ej
    el:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bg
    em:f32[32,16,128] = add ek el
    en:f32[32,16,128] = add ea em
    eo:f32[32,16,256] = concatenate[dimension=2] en cj
    ep:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,16,128] = add_any ep eq
    es:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bk
    et:f32[32,16,128] = add er es
    eu:f32[32,1,16,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 16, 128)
    ] et
    ev:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,16,128] = add_any ev ew
    ey:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bm
    ez:f32[32,16,128] = add ex ey
    fa:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] ez
    fb:f32[32,16,16,128] = add eu fa
    fc:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bc
    fe:f32[32,16,16,128] = add fc fd
    ff:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] be
    fh:f32[32,16,16,128] = add ff fg
    fi:f32[32,16,16,128] = add fe fh
    fj:f32[32,16,16] = mul ck ct
    fk:f32[32,16,16] = div fj cu
    fl:f32[32,16] = reduce_sum[axes=(2,)] fj
    fm:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] fl
    fn:f32[32,16,1] = neg fm
    fo:f32[32,16,16] = mul fn ct
    fp:f32[32,16,16] = mul fo cv
    fq:f32[32,16,16] = add_any fk fp
    fr:f32[32,16,16] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,16,16] ft:bool[32,16,16] fu:f32[32,16,16]. let
          fv:f32[32,16,16] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 16, 16, 1)
    ] fr
    fx:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,16,16,128] = add_any fx fy
    ga:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bi
    gb:f32[32,16,16,128] = add fz ga
    gc:f32[32,16,16,128] = add fi gb
    gd:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,16,16,128] = add_any gd ge
    gg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bo
    gh:f32[32,16,16,128] = add gf gg
    gi:f32[32,16,16,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,16,16,128] = add gi gm
    go:f32[32,16,16,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,16,16,128] gq:bool[32,16,16,128] gr:f32[32,16,16,128]. let
          gs:f32[32,16,16,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,16,16,128] = mul go cz
    gu:f32[32,16,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,16,128] = div gu da
    gw:f32[32,16,128] = mul gv db
    gx:f32[32,16,128] = add_any dt gw
    gy:f32[32,16,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,16,128] = add_any gz ha
    hc:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] cc
    hd:f32[32,16,128] = add hb hc
    he:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hd
    hf:f32[32,16,16,128] = mul he dd
    hg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,16,128] = add_any hg hh
    hj:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ce
    hk:f32[32,16,128] = add hi hj
    hl:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hk
    hm:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,16,16,128] = add_any hm hn
    hp:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] cg
    hq:f32[32,16,16,128] = add ho hp
    hr:f32[32,16,16,128] = add hl hq
    hs:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,16,16,128] = mul hs de
    hu:f32[32,16,16,128] = add_any hf ht
    hv:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,16,16,1] = add_any hv hw
    hy:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] ci
    hz:f32[32,16,16,1] = add hx hy
    ia:f32[32,16,16] = squeeze[dimensions=(3,)] hz
    ib:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,16,1] = add_any ib ic
    ie:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 1)
    ] ca
    if:f32[32,16,1] = add id ie
    ig:f32[32,16] = squeeze[dimensions=(2,)] if
    ih:f32[32,16,128] = mul cj dg
    ii:f32[32,2,16,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,16,16,128] ik:i32[32,2,16,3]. let
          il:f32[32,2,16,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,16,128] = mul ii di
    in:f32[32,16,128] = reduce_sum[axes=(1,)] im
    io:f32[32,16,128] = div in dj
    ip:f32[32,16,128] = mul io dk
    iq:f32[32,16,128] = add_any ih ip
    ir:f32[2,32,16,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,16,128] = scan[
      jaxpr={ lambda ; it:f32[32,16,128] iu:f32[32,16,128] iv:f32[32,16,128] iw:f32[32,16,128]. let
          ix:f32[32,16,128] = mul it iv
          iy:f32[32,16,128] = mul iu iw
          iz:f32[32,16,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,16,128] = sub iq is
    jb:f32[32,16,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 65536.0
    je:f32[] = add jd cm
    jf:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,16,128] = add_any jf jg
    ji:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bs
    jj:f32[32,16,128] = add jh ji
    jk:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jj
    jl:f32[32,16,16,128] = mul jk dp
    jm:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,16,128] = add_any jm jn
    jp:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bu
    jq:f32[32,16,128] = add jo jp
    jr:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jq
    js:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,16,16,128] = add_any js jt
    jv:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bw
    jw:f32[32,16,16,128] = add ju jv
    jx:f32[32,16,16,128] = add jr jw
    jy:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,16,16,128] = mul jy dq
    ka:f32[32,16,16,128] = add_any jl jz
    kb:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,16,16,1] = add_any kb kc
    ke:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] by
    kf:f32[32,16,16,1] = add kd ke
    kg:f32[32,16,16] = squeeze[dimensions=(3,)] kf
    kh:f32[32,16,16] = mul do kg
    ki:f32[32,16,16] = mul ds cn
    kj:f32[32,16,16] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147824cc7a70>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147824c20eb0>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147824c8ebd0; to 'JaxprTracer' at 0x147824c8ee00>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x147824d4c230>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:07:11.288132 22523184681088 run.py:488] Algo bfs step 4 current loss 1.831398, current_train_items 160.
I0219 22:07:11.320681 22523184681088 run.py:488] Algo bfs step 5 current loss 0.704504, current_train_items 192.
I0219 22:07:11.425156 22523184681088 run.py:488] Algo bfs step 6 current loss 0.997817, current_train_items 224.
I0219 22:07:11.651274 22523184681088 run.py:488] Algo bfs step 7 current loss 1.048107, current_train_items 256.
I0219 22:07:11.917636 22523184681088 run.py:488] Algo bfs step 8 current loss 1.047918, current_train_items 288.
I0219 22:07:12.240173 22523184681088 run.py:488] Algo bfs step 9 current loss 1.312654, current_train_items 320.
I0219 22:07:12.271354 22523184681088 run.py:488] Algo bfs step 10 current loss 0.419646, current_train_items 352.
I0219 22:07:12.375663 22523184681088 run.py:488] Algo bfs step 11 current loss 0.656172, current_train_items 384.
I0219 22:07:12.607323 22523184681088 run.py:488] Algo bfs step 12 current loss 0.777799, current_train_items 416.
I0219 22:07:12.875235 22523184681088 run.py:488] Algo bfs step 13 current loss 0.859412, current_train_items 448.
I0219 22:07:13.201201 22523184681088 run.py:488] Algo bfs step 14 current loss 1.017056, current_train_items 480.
I0219 22:07:13.232528 22523184681088 run.py:488] Algo bfs step 15 current loss 0.270512, current_train_items 512.
I0219 22:07:13.336589 22523184681088 run.py:488] Algo bfs step 16 current loss 0.533370, current_train_items 544.
I0219 22:07:13.569476 22523184681088 run.py:488] Algo bfs step 17 current loss 0.526701, current_train_items 576.
I0219 22:07:13.834165 22523184681088 run.py:488] Algo bfs step 18 current loss 0.637873, current_train_items 608.
I0219 22:07:14.151878 22523184681088 run.py:488] Algo bfs step 19 current loss 0.578926, current_train_items 640.
I0219 22:07:14.183225 22523184681088 run.py:488] Algo bfs step 20 current loss 0.175609, current_train_items 672.
I0219 22:07:14.285656 22523184681088 run.py:488] Algo bfs step 21 current loss 0.372186, current_train_items 704.
I0219 22:07:14.513608 22523184681088 run.py:488] Algo bfs step 22 current loss 0.607823, current_train_items 736.
I0219 22:07:14.765950 22523184681088 run.py:488] Algo bfs step 23 current loss 0.588204, current_train_items 768.
I0219 22:07:15.093207 22523184681088 run.py:488] Algo bfs step 24 current loss 0.534163, current_train_items 800.
I0219 22:07:15.123625 22523184681088 run.py:488] Algo bfs step 25 current loss 0.126190, current_train_items 832.
I0219 22:07:15.227299 22523184681088 run.py:488] Algo bfs step 26 current loss 0.320422, current_train_items 864.
I0219 22:07:15.452907 22523184681088 run.py:488] Algo bfs step 27 current loss 0.461014, current_train_items 896.
I0219 22:07:15.708786 22523184681088 run.py:488] Algo bfs step 28 current loss 0.544881, current_train_items 928.
I0219 22:07:16.035076 22523184681088 run.py:488] Algo bfs step 29 current loss 0.425664, current_train_items 960.
I0219 22:07:16.066690 22523184681088 run.py:488] Algo bfs step 30 current loss 0.087803, current_train_items 992.
I0219 22:07:16.170136 22523184681088 run.py:488] Algo bfs step 31 current loss 0.216099, current_train_items 1024.
I0219 22:07:16.398670 22523184681088 run.py:488] Algo bfs step 32 current loss 0.277004, current_train_items 1056.
I0219 22:07:16.660719 22523184681088 run.py:488] Algo bfs step 33 current loss 0.288583, current_train_items 1088.
I0219 22:07:16.979571 22523184681088 run.py:488] Algo bfs step 34 current loss 0.515390, current_train_items 1120.
I0219 22:07:17.010614 22523184681088 run.py:488] Algo bfs step 35 current loss 0.072302, current_train_items 1152.
I0219 22:07:17.114510 22523184681088 run.py:488] Algo bfs step 36 current loss 0.163635, current_train_items 1184.
I0219 22:07:17.342483 22523184681088 run.py:488] Algo bfs step 37 current loss 0.332162, current_train_items 1216.
I0219 22:07:17.608682 22523184681088 run.py:488] Algo bfs step 38 current loss 0.255954, current_train_items 1248.
I0219 22:07:17.932419 22523184681088 run.py:488] Algo bfs step 39 current loss 0.326445, current_train_items 1280.
I0219 22:07:17.963528 22523184681088 run.py:488] Algo bfs step 40 current loss 0.060458, current_train_items 1312.
I0219 22:07:18.067125 22523184681088 run.py:488] Algo bfs step 41 current loss 0.183006, current_train_items 1344.
I0219 22:07:18.297247 22523184681088 run.py:488] Algo bfs step 42 current loss 0.190219, current_train_items 1376.
I0219 22:07:18.558253 22523184681088 run.py:488] Algo bfs step 43 current loss 0.254631, current_train_items 1408.
I0219 22:07:18.882015 22523184681088 run.py:488] Algo bfs step 44 current loss 0.358678, current_train_items 1440.
I0219 22:07:18.912749 22523184681088 run.py:488] Algo bfs step 45 current loss 0.034385, current_train_items 1472.
I0219 22:07:19.015500 22523184681088 run.py:488] Algo bfs step 46 current loss 0.160701, current_train_items 1504.
I0219 22:07:19.240881 22523184681088 run.py:488] Algo bfs step 47 current loss 0.445336, current_train_items 1536.
I0219 22:07:19.500941 22523184681088 run.py:488] Algo bfs step 48 current loss 0.291744, current_train_items 1568.
I0219 22:07:19.816790 22523184681088 run.py:488] Algo bfs step 49 current loss 0.248545, current_train_items 1600.
I0219 22:07:19.847543 22523184681088 run.py:488] Algo bfs step 50 current loss 0.061199, current_train_items 1632.
I0219 22:07:19.921457 22523184681088 run.py:508] (val) algo bfs step 50: {'pi': 0.98046875, 'score': 0.98046875, 'examples_seen': 1632, 'step': 50, 'algorithm': 'bfs'}
I0219 22:07:19.921597 22523184681088 run.py:524] Checkpointing best model, best avg val score was 0.596, current avg val score is 0.980, val scores are: bfs: 0.980
I0219 22:07:20.029418 22523184681088 run.py:488] Algo bfs step 51 current loss 0.092453, current_train_items 1664.
I0219 22:07:20.255934 22523184681088 run.py:488] Algo bfs step 52 current loss 0.197129, current_train_items 1696.
I0219 22:07:20.527047 22523184681088 run.py:488] Algo bfs step 53 current loss 0.192916, current_train_items 1728.
I0219 22:07:20.843513 22523184681088 run.py:488] Algo bfs step 54 current loss 0.198532, current_train_items 1760.
I0219 22:07:20.873877 22523184681088 run.py:488] Algo bfs step 55 current loss 0.025682, current_train_items 1792.
I0219 22:07:20.978227 22523184681088 run.py:488] Algo bfs step 56 current loss 0.088562, current_train_items 1824.
I0219 22:07:21.206120 22523184681088 run.py:488] Algo bfs step 57 current loss 0.118497, current_train_items 1856.
I0219 22:07:21.475794 22523184681088 run.py:488] Algo bfs step 58 current loss 0.169798, current_train_items 1888.
I0219 22:07:21.795380 22523184681088 run.py:488] Algo bfs step 59 current loss 0.276037, current_train_items 1920.
I0219 22:07:21.826846 22523184681088 run.py:488] Algo bfs step 60 current loss 0.039834, current_train_items 1952.
I0219 22:07:21.931307 22523184681088 run.py:488] Algo bfs step 61 current loss 0.085262, current_train_items 1984.
I0219 22:07:22.163087 22523184681088 run.py:488] Algo bfs step 62 current loss 0.099548, current_train_items 2016.
I0219 22:07:22.423830 22523184681088 run.py:488] Algo bfs step 63 current loss 0.163840, current_train_items 2048.
I0219 22:07:22.741737 22523184681088 run.py:488] Algo bfs step 64 current loss 0.165036, current_train_items 2080.
I0219 22:07:22.772660 22523184681088 run.py:488] Algo bfs step 65 current loss 0.021459, current_train_items 2112.
I0219 22:07:22.875793 22523184681088 run.py:488] Algo bfs step 66 current loss 0.083650, current_train_items 2144.
I0219 22:07:23.107938 22523184681088 run.py:488] Algo bfs step 67 current loss 0.156162, current_train_items 2176.
I0219 22:07:23.368139 22523184681088 run.py:488] Algo bfs step 68 current loss 0.153865, current_train_items 2208.
I0219 22:07:23.697357 22523184681088 run.py:488] Algo bfs step 69 current loss 0.147820, current_train_items 2240.
I0219 22:07:23.728738 22523184681088 run.py:488] Algo bfs step 70 current loss 0.015898, current_train_items 2272.
I0219 22:07:23.832985 22523184681088 run.py:488] Algo bfs step 71 current loss 0.050741, current_train_items 2304.
I0219 22:07:24.065387 22523184681088 run.py:488] Algo bfs step 72 current loss 0.079526, current_train_items 2336.
I0219 22:07:24.331266 22523184681088 run.py:488] Algo bfs step 73 current loss 0.129121, current_train_items 2368.
I0219 22:07:24.647554 22523184681088 run.py:488] Algo bfs step 74 current loss 0.141161, current_train_items 2400.
I0219 22:07:24.679079 22523184681088 run.py:488] Algo bfs step 75 current loss 0.021327, current_train_items 2432.
I0219 22:07:24.783405 22523184681088 run.py:488] Algo bfs step 76 current loss 0.052264, current_train_items 2464.
I0219 22:07:25.011605 22523184681088 run.py:488] Algo bfs step 77 current loss 0.079683, current_train_items 2496.
I0219 22:07:25.270723 22523184681088 run.py:488] Algo bfs step 78 current loss 0.135785, current_train_items 2528.
I0219 22:07:25.604201 22523184681088 run.py:488] Algo bfs step 79 current loss 0.157158, current_train_items 2560.
I0219 22:07:25.634610 22523184681088 run.py:488] Algo bfs step 80 current loss 0.006091, current_train_items 2592.
I0219 22:07:25.738150 22523184681088 run.py:488] Algo bfs step 81 current loss 0.038488, current_train_items 2624.
I0219 22:07:25.961968 22523184681088 run.py:488] Algo bfs step 82 current loss 0.053620, current_train_items 2656.
I0219 22:07:26.224800 22523184681088 run.py:488] Algo bfs step 83 current loss 0.098166, current_train_items 2688.
I0219 22:07:26.543682 22523184681088 run.py:488] Algo bfs step 84 current loss 0.132795, current_train_items 2720.
I0219 22:07:26.574546 22523184681088 run.py:488] Algo bfs step 85 current loss 0.011250, current_train_items 2752.
I0219 22:07:26.676893 22523184681088 run.py:488] Algo bfs step 86 current loss 0.019833, current_train_items 2784.
I0219 22:07:26.897271 22523184681088 run.py:488] Algo bfs step 87 current loss 0.260210, current_train_items 2816.
I0219 22:07:27.163866 22523184681088 run.py:488] Algo bfs step 88 current loss 0.109423, current_train_items 2848.
I0219 22:07:27.484885 22523184681088 run.py:488] Algo bfs step 89 current loss 0.136427, current_train_items 2880.
I0219 22:07:27.515406 22523184681088 run.py:488] Algo bfs step 90 current loss 0.018244, current_train_items 2912.
I0219 22:07:27.618877 22523184681088 run.py:488] Algo bfs step 91 current loss 0.045948, current_train_items 2944.
I0219 22:07:27.845448 22523184681088 run.py:488] Algo bfs step 92 current loss 0.338241, current_train_items 2976.
I0219 22:07:28.102488 22523184681088 run.py:488] Algo bfs step 93 current loss 0.109108, current_train_items 3008.
I0219 22:07:28.427454 22523184681088 run.py:488] Algo bfs step 94 current loss 0.488466, current_train_items 3040.
I0219 22:07:28.458559 22523184681088 run.py:488] Algo bfs step 95 current loss 0.008916, current_train_items 3072.
I0219 22:07:28.561200 22523184681088 run.py:488] Algo bfs step 96 current loss 0.030696, current_train_items 3104.
I0219 22:07:28.786002 22523184681088 run.py:488] Algo bfs step 97 current loss 0.084564, current_train_items 3136.
I0219 22:07:29.050040 22523184681088 run.py:488] Algo bfs step 98 current loss 0.116870, current_train_items 3168.
I0219 22:07:29.370433 22523184681088 run.py:488] Algo bfs step 99 current loss 0.106183, current_train_items 3200.
I0219 22:07:29.401060 22523184681088 run.py:488] Algo bfs step 100 current loss 0.006314, current_train_items 3232.
I0219 22:07:29.475131 22523184681088 run.py:508] (val) algo bfs step 100: {'pi': 0.98828125, 'score': 0.98828125, 'examples_seen': 3232, 'step': 100, 'algorithm': 'bfs'}
I0219 22:07:29.475273 22523184681088 run.py:524] Checkpointing best model, best avg val score was 0.980, current avg val score is 0.988, val scores are: bfs: 0.988
I0219 22:07:29.581636 22523184681088 run.py:488] Algo bfs step 101 current loss 0.030676, current_train_items 3264.
I0219 22:07:29.808049 22523184681088 run.py:488] Algo bfs step 102 current loss 0.054577, current_train_items 3296.
I0219 22:07:30.069845 22523184681088 run.py:488] Algo bfs step 103 current loss 0.106083, current_train_items 3328.
I0219 22:07:30.388808 22523184681088 run.py:488] Algo bfs step 104 current loss 0.113035, current_train_items 3360.
I0219 22:07:30.419835 22523184681088 run.py:488] Algo bfs step 105 current loss 0.007772, current_train_items 3392.
I0219 22:07:30.523551 22523184681088 run.py:488] Algo bfs step 106 current loss 0.025676, current_train_items 3424.
I0219 22:07:30.745802 22523184681088 run.py:488] Algo bfs step 107 current loss 0.111032, current_train_items 3456.
I0219 22:07:31.009989 22523184681088 run.py:488] Algo bfs step 108 current loss 0.087046, current_train_items 3488.
I0219 22:07:31.326573 22523184681088 run.py:488] Algo bfs step 109 current loss 0.125531, current_train_items 3520.
I0219 22:07:31.357542 22523184681088 run.py:488] Algo bfs step 110 current loss 0.006098, current_train_items 3552.
I0219 22:07:31.461069 22523184681088 run.py:488] Algo bfs step 111 current loss 0.043995, current_train_items 3584.
I0219 22:07:31.692671 22523184681088 run.py:488] Algo bfs step 112 current loss 0.102159, current_train_items 3616.
I0219 22:07:31.957018 22523184681088 run.py:488] Algo bfs step 113 current loss 0.094426, current_train_items 3648.
I0219 22:07:32.274978 22523184681088 run.py:488] Algo bfs step 114 current loss 0.104117, current_train_items 3680.
I0219 22:07:32.306332 22523184681088 run.py:488] Algo bfs step 115 current loss 0.016871, current_train_items 3712.
I0219 22:07:32.409741 22523184681088 run.py:488] Algo bfs step 116 current loss 0.032893, current_train_items 3744.
I0219 22:07:32.634569 22523184681088 run.py:488] Algo bfs step 117 current loss 0.103850, current_train_items 3776.
I0219 22:07:32.891409 22523184681088 run.py:488] Algo bfs step 118 current loss 0.073952, current_train_items 3808.
I0219 22:07:33.208371 22523184681088 run.py:488] Algo bfs step 119 current loss 0.090112, current_train_items 3840.
I0219 22:07:33.239123 22523184681088 run.py:488] Algo bfs step 120 current loss 0.004652, current_train_items 3872.
I0219 22:07:33.343666 22523184681088 run.py:488] Algo bfs step 121 current loss 0.026723, current_train_items 3904.
I0219 22:07:33.569230 22523184681088 run.py:488] Algo bfs step 122 current loss 0.062184, current_train_items 3936.
I0219 22:07:33.831435 22523184681088 run.py:488] Algo bfs step 123 current loss 0.085774, current_train_items 3968.
I0219 22:07:34.159837 22523184681088 run.py:488] Algo bfs step 124 current loss 0.083773, current_train_items 4000.
I0219 22:07:34.191725 22523184681088 run.py:488] Algo bfs step 125 current loss 0.003149, current_train_items 4032.
I0219 22:07:34.295304 22523184681088 run.py:488] Algo bfs step 126 current loss 0.023593, current_train_items 4064.
I0219 22:07:34.523643 22523184681088 run.py:488] Algo bfs step 127 current loss 0.052667, current_train_items 4096.
I0219 22:07:34.786625 22523184681088 run.py:488] Algo bfs step 128 current loss 0.070027, current_train_items 4128.
I0219 22:07:35.105008 22523184681088 run.py:488] Algo bfs step 129 current loss 0.078575, current_train_items 4160.
I0219 22:07:35.136101 22523184681088 run.py:488] Algo bfs step 130 current loss 0.003372, current_train_items 4192.
I0219 22:07:35.241259 22523184681088 run.py:488] Algo bfs step 131 current loss 0.029682, current_train_items 4224.
I0219 22:07:35.469391 22523184681088 run.py:488] Algo bfs step 132 current loss 0.035861, current_train_items 4256.
I0219 22:07:35.730849 22523184681088 run.py:488] Algo bfs step 133 current loss 0.120010, current_train_items 4288.
I0219 22:07:36.052043 22523184681088 run.py:488] Algo bfs step 134 current loss 0.117067, current_train_items 4320.
I0219 22:07:36.083556 22523184681088 run.py:488] Algo bfs step 135 current loss 0.004225, current_train_items 4352.
I0219 22:07:36.185793 22523184681088 run.py:488] Algo bfs step 136 current loss 0.008450, current_train_items 4384.
I0219 22:07:36.413561 22523184681088 run.py:488] Algo bfs step 137 current loss 0.048538, current_train_items 4416.
I0219 22:07:36.684229 22523184681088 run.py:488] Algo bfs step 138 current loss 0.099143, current_train_items 4448.
I0219 22:07:37.008498 22523184681088 run.py:488] Algo bfs step 139 current loss 0.088909, current_train_items 4480.
I0219 22:07:37.039239 22523184681088 run.py:488] Algo bfs step 140 current loss 0.002896, current_train_items 4512.
I0219 22:07:37.143218 22523184681088 run.py:488] Algo bfs step 141 current loss 0.025207, current_train_items 4544.
I0219 22:07:37.369795 22523184681088 run.py:488] Algo bfs step 142 current loss 0.081802, current_train_items 4576.
I0219 22:07:37.630841 22523184681088 run.py:488] Algo bfs step 143 current loss 0.045552, current_train_items 4608.
I0219 22:07:37.955616 22523184681088 run.py:488] Algo bfs step 144 current loss 0.091269, current_train_items 4640.
I0219 22:07:37.987276 22523184681088 run.py:488] Algo bfs step 145 current loss 0.002704, current_train_items 4672.
I0219 22:07:38.089847 22523184681088 run.py:488] Algo bfs step 146 current loss 0.018390, current_train_items 4704.
I0219 22:07:38.314905 22523184681088 run.py:488] Algo bfs step 147 current loss 0.066313, current_train_items 4736.
I0219 22:07:38.572995 22523184681088 run.py:488] Algo bfs step 148 current loss 0.082773, current_train_items 4768.
I0219 22:07:38.892546 22523184681088 run.py:488] Algo bfs step 149 current loss 0.092396, current_train_items 4800.
I0219 22:07:38.922595 22523184681088 run.py:488] Algo bfs step 150 current loss 0.001583, current_train_items 4832.
I0219 22:07:38.996580 22523184681088 run.py:508] (val) algo bfs step 150: {'pi': 0.990234375, 'score': 0.990234375, 'examples_seen': 4832, 'step': 150, 'algorithm': 'bfs'}
I0219 22:07:38.996718 22523184681088 run.py:524] Checkpointing best model, best avg val score was 0.988, current avg val score is 0.990, val scores are: bfs: 0.990
I0219 22:07:39.103731 22523184681088 run.py:488] Algo bfs step 151 current loss 0.039154, current_train_items 4864.
I0219 22:07:39.334596 22523184681088 run.py:488] Algo bfs step 152 current loss 0.058296, current_train_items 4896.
I0219 22:07:39.600814 22523184681088 run.py:488] Algo bfs step 153 current loss 0.134019, current_train_items 4928.
W0219 22:07:39.615017 22523184681088 samplers.py:155] Increasing hint lengh from 9 to 10
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147824d29720>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478ac759c70; to 'JaxprTracer' at 0x1478ac759950>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac768030>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478ac4f13b0>, in_tracers=(Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[8,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[8,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[8,32,2,16,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,2,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[8,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478ac71ef40; dead>, <weakref at 0x1478ac71eb80; dead>, <weakref at 0x1478ac71e9f0; dead>, <weakref at 0x1478ac71e4a0; to 'JaxprTracer' at 0x1478ac71a450>, <weakref at 0x1478ac71eae0; to 'JaxprTracer' at 0x1478ac71ed10>, <weakref at 0x1478ac71e9a0; to 'JaxprTracer' at 0x1478ac71e1d0>, <weakref at 0x1478ac71e770; to 'JaxprTracer' at 0x1478ac71e090>], out_avals=[ShapedArray(float32[32,16,128]), ShapedArray(float32[32,16,16]), ShapedArray(float32[32,16]), ShapedArray(float32[]), ShapedArray(float32[32,16,16]), ShapedArray(float32[8,32,16,16]), ShapedArray(float32[8,32,16])], primitive=scan, params={'reverse': False, 'length': 8, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,16,1] b:f32[32,16,1] c:f32[32,16] d:f32[1,128] e:f32[256,128]
    f:f32[256,128] g:f32[32,16,16,1] h:f32[32,16,16,1] i:f32[32,16,16] j:f32[1,128]
    k:f32[128,128] l:f32[32,128] m:bool[32,16,16,128] n:f32[32,16,16,128] o:f32[384,128]
    p:f32[384,128] q:f32[128,128] r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128]
    v:f32[128,128] w:f32[128,1] x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128]
    bb:f32[1,128] bc:f32[128] bd:f32[1,128] be:f32[128] bf:f32[1,128] bg:f32[128]
    bh:f32[1,128] bi:f32[128] bj:f32[256,128] bk:f32[128] bl:f32[256,128] bm:f32[128]
    bn:f32[128,128] bo:f32[128] bp:f32[128,128] bq:f32[128] br:f32[384,128] bs:f32[128]
    bt:f32[384,128] bu:f32[128] bv:f32[128,128] bw:f32[128] bx:f32[128,1] by:f32[1]
    bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128] cd:f32[384,128] ce:f32[128]
    cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1] cj:f32[32,16,128] ck:f32[32,16,16]
    cl:f32[32,16] cm:f32[] cn:f32[32,16,16] co:f32[32,16,128] cp:f32[32,16] cq:bool[32,16]
    cr:f32[32,16,1] cs:f32[32,16,256] ct:f32[32,16,16] cu:f32[32,16,1] cv:f32[32,16,1]
    cw:bool[32,16,16] cx:f32[32,16,16,1] cy:f32[32,16,16,128] cz:f32[32,16,16,128]
    da:f32[32,16,128] db:f32[32,16,128] dc:f32[32,16,384] dd:f32[32,16,16,128] de:f32[32,16,16,128]
    df:f32[32,16,16,128] dg:f32[32,16,128] dh:i32[32,2,16,3] di:f32[32,2,16,128]
    dj:f32[32,16,128] dk:f32[32,16,128] dl:f32[2,32,16,128] dm:f32[2,32,16,128] dn:f32[32,16,128]
    do:f32[32,1,1] dp:f32[32,16,16,128] dq:f32[32,16,16,128] dr:f32[32,16,16,128]
    ds:f32[32,1,1]. let
    dt:f32[32,16,128] = mul cj co
    du:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] y
    dw:f32[32,16,128] = add du dv
    dx:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ba
    dz:f32[32,16,128] = add dx dy
    ea:f32[32,16,128] = add dw dz
    eb:f32[32,16] = mul cl cp
    ec:f32[32,16] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,16] ee:bool[32,16] ef:f32[32,16]. let
          eg:f32[32,16] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] ec
    ei:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,16,128] = add_any ei ej
    el:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bg
    em:f32[32,16,128] = add ek el
    en:f32[32,16,128] = add ea em
    eo:f32[32,16,256] = concatenate[dimension=2] en cj
    ep:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,16,128] = add_any ep eq
    es:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bk
    et:f32[32,16,128] = add er es
    eu:f32[32,1,16,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 16, 128)
    ] et
    ev:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,16,128] = add_any ev ew
    ey:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bm
    ez:f32[32,16,128] = add ex ey
    fa:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] ez
    fb:f32[32,16,16,128] = add eu fa
    fc:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bc
    fe:f32[32,16,16,128] = add fc fd
    ff:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] be
    fh:f32[32,16,16,128] = add ff fg
    fi:f32[32,16,16,128] = add fe fh
    fj:f32[32,16,16] = mul ck ct
    fk:f32[32,16,16] = div fj cu
    fl:f32[32,16] = reduce_sum[axes=(2,)] fj
    fm:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] fl
    fn:f32[32,16,1] = neg fm
    fo:f32[32,16,16] = mul fn ct
    fp:f32[32,16,16] = mul fo cv
    fq:f32[32,16,16] = add_any fk fp
    fr:f32[32,16,16] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,16,16] ft:bool[32,16,16] fu:f32[32,16,16]. let
          fv:f32[32,16,16] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 16, 16, 1)
    ] fr
    fx:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,16,16,128] = add_any fx fy
    ga:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bi
    gb:f32[32,16,16,128] = add fz ga
    gc:f32[32,16,16,128] = add fi gb
    gd:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,16,16,128] = add_any gd ge
    gg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bo
    gh:f32[32,16,16,128] = add gf gg
    gi:f32[32,16,16,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,16,16,128] = add gi gm
    go:f32[32,16,16,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,16,16,128] gq:bool[32,16,16,128] gr:f32[32,16,16,128]. let
          gs:f32[32,16,16,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,16,16,128] = mul go cz
    gu:f32[32,16,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,16,128] = div gu da
    gw:f32[32,16,128] = mul gv db
    gx:f32[32,16,128] = add_any dt gw
    gy:f32[32,16,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,16,128] = add_any gz ha
    hc:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] cc
    hd:f32[32,16,128] = add hb hc
    he:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hd
    hf:f32[32,16,16,128] = mul he dd
    hg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,16,128] = add_any hg hh
    hj:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ce
    hk:f32[32,16,128] = add hi hj
    hl:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hk
    hm:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,16,16,128] = add_any hm hn
    hp:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] cg
    hq:f32[32,16,16,128] = add ho hp
    hr:f32[32,16,16,128] = add hl hq
    hs:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,16,16,128] = mul hs de
    hu:f32[32,16,16,128] = add_any hf ht
    hv:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,16,16,1] = add_any hv hw
    hy:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] ci
    hz:f32[32,16,16,1] = add hx hy
    ia:f32[32,16,16] = squeeze[dimensions=(3,)] hz
    ib:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,16,1] = add_any ib ic
    ie:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 1)
    ] ca
    if:f32[32,16,1] = add id ie
    ig:f32[32,16] = squeeze[dimensions=(2,)] if
    ih:f32[32,16,128] = mul cj dg
    ii:f32[32,2,16,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,16,16,128] ik:i32[32,2,16,3]. let
          il:f32[32,2,16,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,16,128] = mul ii di
    in:f32[32,16,128] = reduce_sum[axes=(1,)] im
    io:f32[32,16,128] = div in dj
    ip:f32[32,16,128] = mul io dk
    iq:f32[32,16,128] = add_any ih ip
    ir:f32[2,32,16,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,16,128] = scan[
      jaxpr={ lambda ; it:f32[32,16,128] iu:f32[32,16,128] iv:f32[32,16,128] iw:f32[32,16,128]. let
          ix:f32[32,16,128] = mul it iv
          iy:f32[32,16,128] = mul iu iw
          iz:f32[32,16,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,16,128] = sub iq is
    jb:f32[32,16,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 65536.0
    je:f32[] = add jd cm
    jf:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,16,128] = add_any jf jg
    ji:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bs
    jj:f32[32,16,128] = add jh ji
    jk:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jj
    jl:f32[32,16,16,128] = mul jk dp
    jm:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,16,128] = add_any jm jn
    jp:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bu
    jq:f32[32,16,128] = add jo jp
    jr:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jq
    js:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,16,16,128] = add_any js jt
    jv:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bw
    jw:f32[32,16,16,128] = add ju jv
    jx:f32[32,16,16,128] = add jr jw
    jy:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,16,16,128] = mul jy dq
    ka:f32[32,16,16,128] = add_any jl jz
    kb:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,16,16,1] = add_any kb kc
    ke:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] by
    kf:f32[32,16,16,1] = add kd ke
    kg:f32[32,16,16] = squeeze[dimensions=(3,)] kf
    kh:f32[32,16,16] = mul do kg
    ki:f32[32,16,16] = mul ds cn
    kj:f32[32,16,16] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac7cc8f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x147824d29670>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478ac7595e0; to 'JaxprTracer' at 0x1478ac6f7cc0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478ac7d78f0>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:07:46.316606 22523184681088 run.py:488] Algo bfs step 154 current loss 0.169087, current_train_items 4960.
I0219 22:07:46.348905 22523184681088 run.py:488] Algo bfs step 155 current loss 0.004672, current_train_items 4992.
I0219 22:07:46.451372 22523184681088 run.py:488] Algo bfs step 156 current loss 0.015687, current_train_items 5024.
I0219 22:07:46.679198 22523184681088 run.py:488] Algo bfs step 157 current loss 0.062542, current_train_items 5056.
I0219 22:07:46.944163 22523184681088 run.py:488] Algo bfs step 158 current loss 0.070542, current_train_items 5088.
I0219 22:07:47.304872 22523184681088 run.py:488] Algo bfs step 159 current loss 0.066639, current_train_items 5120.
I0219 22:07:47.336517 22523184681088 run.py:488] Algo bfs step 160 current loss 0.009202, current_train_items 5152.
I0219 22:07:47.439708 22523184681088 run.py:488] Algo bfs step 161 current loss 0.013725, current_train_items 5184.
I0219 22:07:47.666192 22523184681088 run.py:488] Algo bfs step 162 current loss 0.061615, current_train_items 5216.
I0219 22:07:47.933880 22523184681088 run.py:488] Algo bfs step 163 current loss 0.068756, current_train_items 5248.
I0219 22:07:48.285042 22523184681088 run.py:488] Algo bfs step 164 current loss 0.091143, current_train_items 5280.
I0219 22:07:48.315612 22523184681088 run.py:488] Algo bfs step 165 current loss 0.012982, current_train_items 5312.
I0219 22:07:48.420024 22523184681088 run.py:488] Algo bfs step 166 current loss 0.013390, current_train_items 5344.
I0219 22:07:48.647460 22523184681088 run.py:488] Algo bfs step 167 current loss 0.054034, current_train_items 5376.
I0219 22:07:48.907585 22523184681088 run.py:488] Algo bfs step 168 current loss 0.046910, current_train_items 5408.
I0219 22:07:49.270844 22523184681088 run.py:488] Algo bfs step 169 current loss 0.065177, current_train_items 5440.
I0219 22:07:49.301868 22523184681088 run.py:488] Algo bfs step 170 current loss 0.011465, current_train_items 5472.
I0219 22:07:49.405982 22523184681088 run.py:488] Algo bfs step 171 current loss 0.020608, current_train_items 5504.
I0219 22:07:49.629674 22523184681088 run.py:488] Algo bfs step 172 current loss 0.035582, current_train_items 5536.
I0219 22:07:49.894721 22523184681088 run.py:488] Algo bfs step 173 current loss 0.039271, current_train_items 5568.
I0219 22:07:50.257431 22523184681088 run.py:488] Algo bfs step 174 current loss 0.067912, current_train_items 5600.
I0219 22:07:50.288393 22523184681088 run.py:488] Algo bfs step 175 current loss 0.002763, current_train_items 5632.
I0219 22:07:50.393257 22523184681088 run.py:488] Algo bfs step 176 current loss 0.022016, current_train_items 5664.
I0219 22:07:50.624809 22523184681088 run.py:488] Algo bfs step 177 current loss 0.020148, current_train_items 5696.
I0219 22:07:50.884499 22523184681088 run.py:488] Algo bfs step 178 current loss 0.048112, current_train_items 5728.
I0219 22:07:51.247580 22523184681088 run.py:488] Algo bfs step 179 current loss 0.047400, current_train_items 5760.
I0219 22:07:51.278204 22523184681088 run.py:488] Algo bfs step 180 current loss 0.005140, current_train_items 5792.
I0219 22:07:51.381820 22523184681088 run.py:488] Algo bfs step 181 current loss 0.023583, current_train_items 5824.
I0219 22:07:51.609019 22523184681088 run.py:488] Algo bfs step 182 current loss 0.027978, current_train_items 5856.
I0219 22:07:51.875501 22523184681088 run.py:488] Algo bfs step 183 current loss 0.045596, current_train_items 5888.
I0219 22:07:52.227716 22523184681088 run.py:488] Algo bfs step 184 current loss 0.055837, current_train_items 5920.
I0219 22:07:52.258861 22523184681088 run.py:488] Algo bfs step 185 current loss 0.001927, current_train_items 5952.
I0219 22:07:52.363658 22523184681088 run.py:488] Algo bfs step 186 current loss 0.010550, current_train_items 5984.
I0219 22:07:52.594326 22523184681088 run.py:488] Algo bfs step 187 current loss 0.029824, current_train_items 6016.
I0219 22:07:52.861697 22523184681088 run.py:488] Algo bfs step 188 current loss 0.031777, current_train_items 6048.
I0219 22:07:53.217379 22523184681088 run.py:488] Algo bfs step 189 current loss 0.047203, current_train_items 6080.
I0219 22:07:53.247984 22523184681088 run.py:488] Algo bfs step 190 current loss 0.005190, current_train_items 6112.
I0219 22:07:53.351353 22523184681088 run.py:488] Algo bfs step 191 current loss 0.020680, current_train_items 6144.
I0219 22:07:53.576431 22523184681088 run.py:488] Algo bfs step 192 current loss 0.016556, current_train_items 6176.
I0219 22:07:53.828826 22523184681088 run.py:488] Algo bfs step 193 current loss 0.048394, current_train_items 6208.
I0219 22:07:54.177356 22523184681088 run.py:488] Algo bfs step 194 current loss 0.050290, current_train_items 6240.
I0219 22:07:54.208144 22523184681088 run.py:488] Algo bfs step 195 current loss 0.028145, current_train_items 6272.
I0219 22:07:54.311324 22523184681088 run.py:488] Algo bfs step 196 current loss 0.019698, current_train_items 6304.
I0219 22:07:54.534629 22523184681088 run.py:488] Algo bfs step 197 current loss 0.018905, current_train_items 6336.
I0219 22:07:54.783831 22523184681088 run.py:488] Algo bfs step 198 current loss 0.041648, current_train_items 6368.
W0219 22:07:54.798406 22523184681088 samplers.py:155] Increasing hint lengh from 10 to 11
--- Logging error ---
Traceback (most recent call last):
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1083, in emit
    msg = self.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 927, in format
    return fmt.format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1018, in format
    return prefix + super(PythonFormatter, self).format(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 663, in format
    record.message = record.getMessage()
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 367, in getMessage
    msg = msg % self.args
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 776, in __float__
    return self.aval._float(self)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/core.py", line 1516, in error
    raise ConcretizationTypeError(arg, fname_context)
jax.errors.ConcretizationTypeError: Abstract tracer value encountered where concrete value is expected: traced array with shape float32[].
The problem arose with the `float` function. If trying to convert the data type of a value, try using `x.astype(float)` or `jnp.array(x, float)` instead.

See https://jax.readthedocs.io/en/latest/errors.html#jax.errors.ConcretizationTypeError
Call stack:
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 553, in <module>
    app.run(main)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 308, in run
    _run_main(main, args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/app.py", line 254, in _run_main
    sys.exit(main(argv))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/examples/run.py", line 480, in main
    cur_loss = train_model.feedback(rng_key, feedback, length_and_algo_idx)
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 374, in feedback
    loss, self._device_params, self._device_opt_state = self.jitted_feedback(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 257, in cache_miss
    outs, out_flat, out_tree, args_flat, jaxpr = _python_pjit_helper(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 163, in _python_pjit_helper
    args_flat, _, params, in_tree, out_tree, _, _, _ = infer_params_fn(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 317, in infer_params
    return pjit.common_infer_params(pjit_info_args, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 493, in common_infer_params
    jaxpr, consts, canonicalized_out_shardings_flat, out_layouts_flat = _pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 996, in _pjit_jaxpr
    jaxpr, final_consts, out_type = _create_pjit_jaxpr(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 349, in memoized_fun
    ans = call(fun, *args)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/pjit.py", line 936, in _create_pjit_jaxpr
    jaxpr, global_out_avals, consts = pe.trace_to_jaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2288, in trace_to_jaxpr_dynamic
    jaxpr, out_avals, consts = trace_to_subjaxpr_dynamic(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 2310, in trace_to_subjaxpr_dynamic
    ans = fun.call_wrapped(*in_tracers_)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 319, in _feedback
    lss, grads = jax.value_and_grad(self._loss)(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/traceback_util.py", line 179, in reraise_with_filtered_traceback
    return fun(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 735, in value_and_grad_f
    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/api.py", line 2223, in _vjp
    out_primal, out_vjp = ad.vjp(
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 142, in vjp
    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/ad.py", line 131, in linearize
    jaxpr, out_pvals, consts = pe.trace_to_jaxpr_nounits(jvpfun_flat, in_pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/profiler.py", line 336, in wrapper
    return func(*args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/interpreters/partial_eval.py", line 774, in trace_to_jaxpr_nounits
    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/jax/_src/linear_util.py", line 191, in call_wrapped
    ans = self.f(*args, **dict(self.params, **kwargs))
  File "/rds/user/ar2217/hpc-work/L65/clrs-ls65/clrs/_src/baselines.py", line 435, in _loss
    logging.info('Regularised loss %f MSE loss %f total_loss %f', regularisation_loss, mse_loss, total_loss)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 409, in info
    log(INFO, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 556, in log
    _absl_logger.log(standard_level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1124, in log
    super(ABSLLogger, self).log(level, msg, *args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1512, in log
    self._log(level, msg, args, **kwargs)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1589, in _log
    self.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 1141, in handle
    self.callHandlers(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 1661, in callHandlers
    hdlr.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 981, in handle
    return self._current_handler.handle(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/logging/__init__.py", line 952, in handle
    self.emit(record)
  File "/home/ar2217/.conda/envs/env_L65/lib/python3.9/site-packages/absl/logging/__init__.py", line 918, in emit
    super(PythonHandler, self).emit(record)
Message: 'Regularised loss %f MSE loss %f total_loss %f'
Arguments: (Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478ac673960>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x147827480040; to 'JaxprTracer' at 0x14782741e3b0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = mul b a in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478275735b0>, name_stack=NameStack(stack=(Transform(name='jvp'),)))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478252c9cd0>, in_tracers=(Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[256,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[384,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[128,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[9,32,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,256]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(bool[9,32,16,16]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,384]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(int32[9,32,2,16,3]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,2,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,2,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,1,1]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,16,16,128]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[9,32,1,1]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x1478273fe900; dead>, <weakref at 0x1478273fed10; dead>, <weakref at 0x1478273fe400; dead>, <weakref at 0x1478273fe680; to 'JaxprTracer' at 0x14782751a040>, <weakref at 0x1478273fe1d0; to 'JaxprTracer' at 0x14782751a4a0>, <weakref at 0x1478273fee50; to 'JaxprTracer' at 0x14782751a950>, <weakref at 0x1478273feef0; to 'JaxprTracer' at 0x1478ac69b540>], out_avals=[ShapedArray(float32[32,16,128]), ShapedArray(float32[32,16,16]), ShapedArray(float32[32,16]), ShapedArray(float32[]), ShapedArray(float32[32,16,16]), ShapedArray(float32[9,32,16,16]), ShapedArray(float32[9,32,16])], primitive=scan, params={'reverse': False, 'length': 9, 'unroll': 1, 'jaxpr': { lambda ; a:f32[32,16,1] b:f32[32,16,1] c:f32[32,16] d:f32[1,128] e:f32[256,128]
    f:f32[256,128] g:f32[32,16,16,1] h:f32[32,16,16,1] i:f32[32,16,16] j:f32[1,128]
    k:f32[128,128] l:f32[32,128] m:bool[32,16,16,128] n:f32[32,16,16,128] o:f32[384,128]
    p:f32[384,128] q:f32[128,128] r:f32[128,1] s:f32[384,1] t:f32[384,128] u:f32[384,128]
    v:f32[128,128] w:f32[128,1] x:f32[1,128] y:f32[128] z:f32[1,128] ba:f32[128]
    bb:f32[1,128] bc:f32[128] bd:f32[1,128] be:f32[128] bf:f32[1,128] bg:f32[128]
    bh:f32[1,128] bi:f32[128] bj:f32[256,128] bk:f32[128] bl:f32[256,128] bm:f32[128]
    bn:f32[128,128] bo:f32[128] bp:f32[128,128] bq:f32[128] br:f32[384,128] bs:f32[128]
    bt:f32[384,128] bu:f32[128] bv:f32[128,128] bw:f32[128] bx:f32[128,1] by:f32[1]
    bz:f32[384,1] ca:f32[1] cb:f32[384,128] cc:f32[128] cd:f32[384,128] ce:f32[128]
    cf:f32[128,128] cg:f32[128] ch:f32[128,1] ci:f32[1] cj:f32[32,16,128] ck:f32[32,16,16]
    cl:f32[32,16] cm:f32[] cn:f32[32,16,16] co:f32[32,16,128] cp:f32[32,16] cq:bool[32,16]
    cr:f32[32,16,1] cs:f32[32,16,256] ct:f32[32,16,16] cu:f32[32,16,1] cv:f32[32,16,1]
    cw:bool[32,16,16] cx:f32[32,16,16,1] cy:f32[32,16,16,128] cz:f32[32,16,16,128]
    da:f32[32,16,128] db:f32[32,16,128] dc:f32[32,16,384] dd:f32[32,16,16,128] de:f32[32,16,16,128]
    df:f32[32,16,16,128] dg:f32[32,16,128] dh:i32[32,2,16,3] di:f32[32,2,16,128]
    dj:f32[32,16,128] dk:f32[32,16,128] dl:f32[2,32,16,128] dm:f32[2,32,16,128] dn:f32[32,16,128]
    do:f32[32,1,1] dp:f32[32,16,16,128] dq:f32[32,16,16,128] dr:f32[32,16,16,128]
    ds:f32[32,1,1]. let
    dt:f32[32,16,128] = mul cj co
    du:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] a x
    dv:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] y
    dw:f32[32,16,128] = add du dv
    dx:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] b z
    dy:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ba
    dz:f32[32,16,128] = add dx dy
    ea:f32[32,16,128] = add dw dz
    eb:f32[32,16] = mul cl cp
    ec:f32[32,16] = pjit[
      name=_where
      jaxpr={ lambda ; ed:f32[32,16] ee:bool[32,16] ef:f32[32,16]. let
          eg:f32[32,16] = select_n ee ed ef
        in (eg,) }
    ] eb cq c
    eh:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] ec
    ei:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eh d
    ej:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cr bf
    ek:f32[32,16,128] = add_any ei ej
    el:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bg
    em:f32[32,16,128] = add ek el
    en:f32[32,16,128] = add ea em
    eo:f32[32,16,256] = concatenate[dimension=2] en cj
    ep:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo e
    eq:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bj
    er:f32[32,16,128] = add_any ep eq
    es:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bk
    et:f32[32,16,128] = add er es
    eu:f32[32,1,16,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 2, 3)
      shape=(32, 1, 16, 128)
    ] et
    ev:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] eo f
    ew:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] cs bl
    ex:f32[32,16,128] = add_any ev ew
    ey:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bm
    ez:f32[32,16,128] = add ex ey
    fa:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] ez
    fb:f32[32,16,16,128] = add eu fa
    fc:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] g bb
    fd:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bc
    fe:f32[32,16,16,128] = add fc fd
    ff:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] h bd
    fg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] be
    fh:f32[32,16,16,128] = add ff fg
    fi:f32[32,16,16,128] = add fe fh
    fj:f32[32,16,16] = mul ck ct
    fk:f32[32,16,16] = div fj cu
    fl:f32[32,16] = reduce_sum[axes=(2,)] fj
    fm:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1)
      shape=(32, 16, 1)
    ] fl
    fn:f32[32,16,1] = neg fm
    fo:f32[32,16,16] = mul fn ct
    fp:f32[32,16,16] = mul fo cv
    fq:f32[32,16,16] = add_any fk fp
    fr:f32[32,16,16] = pjit[
      name=_where
      jaxpr={ lambda ; fs:f32[32,16,16] ft:bool[32,16,16] fu:f32[32,16,16]. let
          fv:f32[32,16,16] = select_n ft fs fu
        in (fv,) }
    ] fq cw i
    fw:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 2)
      shape=(32, 16, 16, 1)
    ] fr
    fx:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] fw j
    fy:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cx bh
    fz:f32[32,16,16,128] = add_any fx fy
    ga:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bi
    gb:f32[32,16,16,128] = add fz ga
    gc:f32[32,16,16,128] = add fi gb
    gd:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc k
    ge:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bn
    gf:f32[32,16,16,128] = add_any gd ge
    gg:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bo
    gh:f32[32,16,16,128] = add gf gg
    gi:f32[32,16,16,128] = add fb gh
    gj:f32[32,128] = dot_general[
      dimension_numbers=(([1], [0]), ([], []))
      preferred_element_type=float32
    ] l bp
    gk:f32[32,128] = broadcast_in_dim[broadcast_dimensions=(1,) shape=(32, 128)] bq
    gl:f32[32,128] = add gj gk
    gm:f32[32,1,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 3)
      shape=(32, 1, 1, 128)
    ] gl
    gn:f32[32,16,16,128] = add gi gm
    go:f32[32,16,16,128] = pjit[
      name=_where
      jaxpr={ lambda ; gp:f32[32,16,16,128] gq:bool[32,16,16,128] gr:f32[32,16,16,128]. let
          gs:f32[32,16,16,128] = select_n gq gr gp
        in (gs,) }
    ] gn m n
    gt:f32[32,16,16,128] = mul go cz
    gu:f32[32,16,128] = reduce_sum[axes=(1,)] gt
    gv:f32[32,16,128] = div gu da
    gw:f32[32,16,128] = mul gv db
    gx:f32[32,16,128] = add_any dt gw
    gy:f32[32,16,384] = concatenate[dimension=2] en cj gx
    gz:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy o
    ha:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cb
    hb:f32[32,16,128] = add_any gz ha
    hc:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] cc
    hd:f32[32,16,128] = add hb hc
    he:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hd
    hf:f32[32,16,16,128] = mul he dd
    hg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy p
    hh:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc cd
    hi:f32[32,16,128] = add_any hg hh
    hj:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] ce
    hk:f32[32,16,128] = add hi hj
    hl:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] hk
    hm:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc q
    hn:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy cf
    ho:f32[32,16,16,128] = add_any hm hn
    hp:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] cg
    hq:f32[32,16,16,128] = add ho hp
    hr:f32[32,16,16,128] = add hl hq
    hs:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] hr
    ht:f32[32,16,16,128] = mul hs de
    hu:f32[32,16,16,128] = add_any hf ht
    hv:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] hu r
    hw:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] df ch
    hx:f32[32,16,16,1] = add_any hv hw
    hy:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] ci
    hz:f32[32,16,16,1] = add hx hy
    ia:f32[32,16,16] = squeeze[dimensions=(3,)] hz
    ib:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy s
    ic:f32[32,16,1] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bz
    id:f32[32,16,1] = add_any ib ic
    ie:f32[32,16,1] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 1)
    ] ca
    if:f32[32,16,1] = add id ie
    ig:f32[32,16] = squeeze[dimensions=(2,)] if
    ih:f32[32,16,128] = mul cj dg
    ii:f32[32,2,16,128] = pjit[
      name=take_along_axis
      jaxpr={ lambda ; ij:f32[32,16,16,128] ik:i32[32,2,16,3]. let
          il:f32[32,2,16,128] = gather[
            dimension_numbers=GatherDimensionNumbers(offset_dims=(3,), collapsed_slice_dims=(0, 1, 2), start_index_map=(0, 1, 2))
            fill_value=0
            indices_are_sorted=False
            mode=GatherScatterMode.FILL_OR_DROP
            slice_sizes=(1, 1, 1, 128)
            unique_indices=False
          ] ij ik
        in (il,) }
    ] gn dh
    im:f32[32,2,16,128] = mul ii di
    in:f32[32,16,128] = reduce_sum[axes=(1,)] im
    io:f32[32,16,128] = div in dj
    ip:f32[32,16,128] = mul io dk
    iq:f32[32,16,128] = add_any ih ip
    ir:f32[2,32,16,128] = transpose[permutation=(1, 0, 2, 3)] ii
    is:f32[32,16,128] = scan[
      jaxpr={ lambda ; it:f32[32,16,128] iu:f32[32,16,128] iv:f32[32,16,128] iw:f32[32,16,128]. let
          ix:f32[32,16,128] = mul it iv
          iy:f32[32,16,128] = mul iu iw
          iz:f32[32,16,128] = add_any ix iy
        in (iz,) }
      length=2
      linear=(True, True, False, False)
      num_carry=1
      num_consts=0
      reverse=False
      unroll=1
    ] cj ir dl dm
    ja:f32[32,16,128] = sub iq is
    jb:f32[32,16,128] = mul ja dn
    jc:f32[] = reduce_sum[axes=(0, 1, 2)] jb
    jd:f32[] = div jc 65536.0
    je:f32[] = add jd cm
    jf:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy t
    jg:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc br
    jh:f32[32,16,128] = add_any jf jg
    ji:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bs
    jj:f32[32,16,128] = add jh ji
    jk:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jj
    jl:f32[32,16,16,128] = mul jk dp
    jm:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] gy u
    jn:f32[32,16,128] = dot_general[
      dimension_numbers=(([2], [0]), ([], []))
      preferred_element_type=float32
    ] dc bt
    jo:f32[32,16,128] = add_any jm jn
    jp:f32[32,16,128] = broadcast_in_dim[
      broadcast_dimensions=(2,)
      shape=(32, 16, 128)
    ] bu
    jq:f32[32,16,128] = add jo jp
    jr:f32[32,16,1,128] = broadcast_in_dim[
      broadcast_dimensions=(0, 1, 3)
      shape=(32, 16, 1, 128)
    ] jq
    js:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] gc v
    jt:f32[32,16,16,128] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] cy bv
    ju:f32[32,16,16,128] = add_any js jt
    jv:f32[32,16,16,128] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 128)
    ] bw
    jw:f32[32,16,16,128] = add ju jv
    jx:f32[32,16,16,128] = add jr jw
    jy:f32[32,16,16,128] = transpose[permutation=(0, 2, 1, 3)] jx
    jz:f32[32,16,16,128] = mul jy dq
    ka:f32[32,16,16,128] = add_any jl jz
    kb:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] ka w
    kc:f32[32,16,16,1] = dot_general[
      dimension_numbers=(([3], [0]), ([], []))
      preferred_element_type=float32
    ] dr bx
    kd:f32[32,16,16,1] = add_any kb kc
    ke:f32[32,16,16,1] = broadcast_in_dim[
      broadcast_dimensions=(3,)
      shape=(32, 16, 16, 1)
    ] by
    kf:f32[32,16,16,1] = add kd ke
    kg:f32[32,16,16] = squeeze[dimensions=(3,)] kf
    kh:f32[32,16,16] = mul do kg
    ki:f32[32,16,16] = mul ds cn
    kj:f32[32,16,16] = add kh ki
  in (gx, ia, ig, je, kj, ia, ig) }, 'linear': (False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False), 'num_consts': 61, 'num_carry': 5}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478275590f0>, name_stack=NameStack(stack=(Transform(name='jvp'), Scope(name='net'))))), Traced<ShapedArray(float32[])>with<JVPTrace(level=3/0)> with
  primal = Traced<ShapedArray(float32[])>with<DynamicJaxprTrace(level=1/0)>
  tangent = Traced<ShapedArray(float32[])>with<JaxprTrace(level=2/0)> with
    pval = (ShapedArray(float32[]), None)
    recipe = JaxprEqnRecipe(eqn_id=<object object at 0x1478ac673860>, in_tracers=(Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>, Traced<ShapedArray(float32[]):JaxprTrace(level=2/0)>), out_tracer_refs=[<weakref at 0x14782741ea90; to 'JaxprTracer' at 0x14782741e1d0>], out_avals=[ShapedArray(float32[])], primitive=pjit, params={'jaxpr': { lambda ; a:f32[] b:f32[]. let c:f32[] = add a b in (c,) }, 'in_shardings': (UnspecifiedValue, UnspecifiedValue), 'out_shardings': (UnspecifiedValue,), 'resource_env': None, 'donated_invars': (False, False), 'name': 'fn', 'keep_unused': False, 'inline': True}, effects=set(), source_info=SourceInfo(traceback=<jaxlib.xla_extension.Traceback object at 0x1478274b34b0>, name_stack=NameStack(stack=(Transform(name='jvp'),)))))
I0219 22:08:01.786046 22523184681088 run.py:488] Algo bfs step 199 current loss 0.181960, current_train_items 6400.
I0219 22:08:01.819097 22523184681088 run.py:488] Algo bfs step 200 current loss 0.001422, current_train_items 6432.
I0219 22:08:01.898363 22523184681088 run.py:508] (val) algo bfs step 200: {'pi': 0.9892578125, 'score': 0.9892578125, 'examples_seen': 6432, 'step': 200, 'algorithm': 'bfs'}
I0219 22:08:01.898512 22523184681088 run.py:527] Not saving new best model, best avg val score was 0.990, current avg val score is 0.989, val scores are: bfs: 0.989
I0219 22:08:02.003210 22523184681088 run.py:488] Algo bfs step 201 current loss 0.025163, current_train_items 6464.
I0219 22:08:02.234671 22523184681088 run.py:488] Algo bfs step 202 current loss 0.034994, current_train_items 6496.
I0219 22:08:02.507045 22523184681088 run.py:488] Algo bfs step 203 current loss 0.027795, current_train_items 6528.
I0219 22:08:02.905692 22523184681088 run.py:488] Algo bfs step 204 current loss 0.041220, current_train_items 6560.
I0219 22:08:02.936870 22523184681088 run.py:488] Algo bfs step 205 current loss 0.001135, current_train_items 6592.
I0219 22:08:03.041010 22523184681088 run.py:488] Algo bfs step 206 current loss 0.026476, current_train_items 6624.
I0219 22:08:03.274814 22523184681088 run.py:488] Algo bfs step 207 current loss 0.018225, current_train_items 6656.
I0219 22:08:03.534223 22523184681088 run.py:488] Algo bfs step 208 current loss 0.040142, current_train_items 6688.
I0219 22:08:03.944042 22523184681088 run.py:488] Algo bfs step 209 current loss 0.045081, current_train_items 6720.
I0219 22:08:03.976285 22523184681088 run.py:488] Algo bfs step 210 current loss 0.000854, current_train_items 6752.
I0219 22:08:04.080231 22523184681088 run.py:488] Algo bfs step 211 current loss 0.021182, current_train_items 6784.
I0219 22:08:04.305613 22523184681088 run.py:488] Algo bfs step 212 current loss 0.025663, current_train_items 6816.
I0219 22:08:04.565921 22523184681088 run.py:488] Algo bfs step 213 current loss 0.040329, current_train_items 6848.
I0219 22:08:04.971589 22523184681088 run.py:488] Algo bfs step 214 current loss 0.064412, current_train_items 6880.
I0219 22:08:05.003760 22523184681088 run.py:488] Algo bfs step 215 current loss 0.001421, current_train_items 6912.
I0219 22:08:05.108083 22523184681088 run.py:488] Algo bfs step 216 current loss 0.013868, current_train_items 6944.
slurmstepd: error: *** JOB 44999834 ON gpu-q-1 CANCELLED AT 2024-02-19T22:08:05 ***
